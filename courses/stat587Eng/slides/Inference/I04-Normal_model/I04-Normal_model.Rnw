\documentclass[handout]{beamer}

\usepackage{verbatim,multicol,amsmath}

\input{../../frontmatter}
\input{../../commands}

\title{I04 - Normal model}

% \newenvironment{remark}[1][Remark]{\begin{trivlist}
% \item[\hskip \labelsep {\bfseries #1}]}{\end{trivlist}}

<<options, results='hide', echo=FALSE, purl=FALSE>>=
opts_chunk$set(comment=NA, 
               fig.width=6, fig.height=5, 
               size='tiny', 
               out.width='0.8\\textwidth', 
               fig.align='center', 
               message=FALSE,
               echo=FALSE,
               cache=TRUE)
options(width=120)
@

<<libraries, message=FALSE, warning=FALSE, cache=FALSE>>=
library("dplyr")
library("tidyr")
library("ggplot2")
library("MCMCpack") # for dinvgamma function
@

<<set_seed, echo=FALSE>>=
set.seed(2)
@

\begin{document}

\begin{frame}
\maketitle
\end{frame}


\begin{frame}
\frametitle{Outline}
\begin{itemize}
\item Normal model with known population variance
\item Normal model with known population mean
\item Normal model
\end{itemize}

\end{frame}



\begin{frame}
\frametitle{Corn yield}

For the following examples, we will consider measuring corn yield 
on fields. 
We will base our analyses on the following true \alert{parameter values}:
\begin{itemize}
\item Mean yield per field is 200 bushels per acre
\item Standard deviation of yield per field is 20 bushels per acre
\end{itemize}

\vspace{0.1in} \pause

In the following analyses, we will be assuming
\begin{itemize}
\item \alert{Population mean is unknown} while population SD is known to be 20
\item Population mean is known to be 200 while \alert{population SD is unknown}
\item \alert{Population mean and population SD are both unknown}.
\end{itemize}

\end{frame}




\section{Normal model with known population variance}
\begin{frame}
\frametitle{Normal model with known population variance}

Suppose $Y_i \ind N(\mu,v^2)$ and we assume the default prior $p(\mu)\propto 1$. 

\vspace{0.1in} \pause

This ``prior'' is actually not a distribution at all, since its integral is not
finite. \pause Nonetheless, we can still use it to derive a posterior. 

\vspace{0.1in} \pause

If you work through the math (lots of algebra and a little calculus), 
\pause 
you will find 
\[ 
\mu|y \sim N(\overline{y}, v^2/n).
\]
\pause
This looks exactly like the likelihood, but now it is normalized, i.e. it 
integrates to 1 and therefore it is a valid probability density function.

\vspace{0.1in} \pause

The Bayes estimator is 
\[ 
E[\mu|y] = \pause \overline{y}.
\]

\end{frame}


\begin{frame}[fragile]
<<population_parameters, echo=FALSE>>=
m <- 200
@

<<data, echo=TRUE, dependson="population_parameters">>=
v <- 20 # Population standard deviation is known
n <- 9
y <- rnorm(n, mean = m, sd = v); mean(y)
@

<<data_plot, fig.height=4, dependson=c("population_parameters","data")>>=
curve(dnorm(x, 
            mean = mean(y), 
            sd = v/sqrt(n)), 
      mean(y)-3*v/sqrt(n), 
      mean(y)+3*v/sqrt(n), 
      xlab = expression(mu),
      ylab = expression(paste("p(",mu,"|y)")),
      main = "Posterior")
abline(v=mean(y), col='red')
@
\end{frame}


\begin{frame}[fragile]
\frametitle{Credible intervals}

We can obtain credible intevals directly.
<<echo=TRUE>>=
a <- .05
qnorm(c(a/2,1-a/2), mean(y), sd = v/sqrt(n))
@

Or we can use the fact that
\[
\frac{\mu-\overline{y}}{v/\sqrt{n}} \pause = Z \sim N(0,1)
\]
to construct the interval using
\[
\overline{y} \pm z_{a/2} v/\sqrt{n}
\]
where $a/2 = \int_{z_{a/2}}^{\infty} \frac{1}{\sqrt{2\pi}}e^{-x^2/2} dx$,
i.e. the area to the right of $z_{a/2}$ under the pdf of a standard normal is
$a/2$.

\pause

<<echo=TRUE, dependson=c("population_parameters","data")>>=
mean(y) + c(-1,1)*qnorm(1-a/2)*v/sqrt(n) # equivalently mean(y) + qnorm(c(a/2,1-a/2))*v/sqrt(n)
@

\end{frame}



\subsection{Normal model with known population mean}
\begin{frame}
\frametitle{Normal model with known population mean}

Suppose $Y_i \ind N(m,\sigma^2)$ and we assume the default prior
$p(\sigma^2)\propto \frac{1}{\sigma^2} \I(\sigma^2>0)$.

\vspace{0.1in} \pause

Again, this ``prior'' is actually not a distribution at all,
since its integral is not
finite.
\pause
Nonetheless, we can still use it to derive a posterior.

\vspace{0.1in} \pause

If you work through the math (lots of algebra and a little calculus),
\pause
you will find
\[
\sigma^2|y \sim IG\left(\frac{n}{2}, \frac{\sum_{i=1}^n(y_i-m)^2}{2}\right)
\]
\pause
where $IG$ indicates an \href{https://en.wikipedia.org/wiki/Inverse-gamma_distribution}{inverse gamma} distribution.

\vspace{0.1in} \pause

The Bayes estimator is
\[
E[\sigma^2|y] = \frac{\frac{\sum_{i=1}^n(y_i-m)^2}{2}}{\frac{n}{2}-1} =
\frac{\sum_{i=1}^n(y_i-m)^2}{n-2}
\mbox{ for }n>2
\]

\end{frame}


\begin{frame}[fragile]
\frametitle{}
<<variance_posterior, echo=TRUE, fig.height=3.5, dependson="data">>=
m <- 200 # Population mean is known
SS <- sum((y-m)^2); SS/(n-2)
curve(MCMCpack::dinvgamma(x, shape = n/2, scale = SS/2), 0, 3*SS/n,
      xlab = expression(sigma^2),
      ylab = expression(paste("p(",sigma^2,"|y)")),
      main = "Posterior")
abline(v = SS/(n-2), col='red')
@
\end{frame}



\begin{frame}[fragile]
\frametitle{Credible intervals for variance - exact}

For some reason, nobody has created a function to calculate the quantiles of
an inverse gamma. \pause So here is one

<<qinvgamma, echo=TRUE>>=
qinvgamma <- function(p, shape, scale = 1) {
  1/qgamma(1-p, shape = shape, rate = scale)
}
@

\pause
This function is slightly confusing because the `scale` parameter for the
inverse gamma is the `rate` parameter for the gamma.

\vspace{0.2in} \pause

Now we can use this to calculate our credible intervals

<<ci_for_variance, dependson=c("variance_posterior","qinvgamma","data"), echo=TRUE>>=
SS <- sum((y-m)^2)
(q <- qinvgamma(c(.025,.975), shape = n/2, scale = SS/2))
@

\end{frame}



\begin{frame}[fragile]
\frametitle{Credible intervals for variance - estimates via simulation}

We can also obtain estimates of the interval endpoints by taking a bunch of
simulated draws from the inverse gamma distribution and finding their sample
quantiles.

<<ci_sim, dependson=c("variance_posterior","data"), echo=TRUE>>=
draws <- MCMCpack::rinvgamma(1e5, shape = n/2, scale = SS/2)
quantile(draws, c(a/2, 1-a/2))
@

If you don't have the MCMCpack library,
you can draw from the gamma distribution and then invert the draws
(which is the same trick that is used for the qinvgamma function).
\pause

<<ci_sim2, dependson=c("variance_posterior","data"), echo=TRUE>>=
draws <- 1/rgamma(1e5, shape = n/2, rate = SS/2)
quantile(draws, c(a/2, 1-a/2))
@
\pause
These are both Monte Carlo estimates of the true credible intervals and these estimates
improve as the number of simultions increase.

\end{frame}


\begin{frame}[fragile]
\frametitle{Posterior and credible intervals for standard deviation}

\small

\vspace{-0.1in}

<<sd_posterior, echo=TRUE, fig.height=2.5, dependson="variance_draws">>=
sqrt(q) # Take square root of end points of the CI for the variance to get the exact intervals
hist(sqrt(draws), 1001, xlab = expression(sigma), ylab = expression(paste("p(",sigma,"|y)")),
     main = "Posterior for standard deviation", probability = TRUE)
abline(v=sqrt(q), col="red")
@

\pause

There is actually a more sophisticated way to do this via
\alert{transformations}. You can learn this technique in STAT 588.

\end{frame}


\begin{frame}
\frametitle{Normal model (unknown population mean and variance)}

\small

Suppose $Y_i \ind N(\mu,\sigma^2)$ and we assume the default prior
$p(\mu,\sigma^2)\propto \frac{1}{\sigma^2} \I(\sigma^2>0)$.

\vspace{0.1in} \pause

Again, this ``prior'' is actually not a distribution at all,
since its integral is not finite.
\pause
Nonetheless, we can still use it to derive a posterior.

\vspace{0.1in} \pause

If you work through the math (lots of algebra and a little calculus),
\pause
you will find
\[ \begin{array}{rl}
\mu|\sigma^2,y &\sim N(\overline{y}, \sigma^2/n) \\
\sigma^2|y &\sim IG\left(\frac{n-1}{2}, \frac{\sum_{i=1}^n(y_i-\overline{y})^2}{2}\right)
\end{array} \]
\pause

The joint posterior is obtained using
\[
p(\mu,\sigma^2|y) = p(\mu|\sigma^2,y)p(\sigma^2|y).
\]

\vspace{0.1in} \pause

The Bayes estimator is
\[ \begin{array}{rl}
E[\mu|y] &= \overline{y} \\
E[\sigma^2|y] &= \frac{\frac{\sum_{i=1}^n(y_i-\overline{y})^2}{2}}{\frac{n-1}{2}-1} =
\frac{\sum_{i=1}^n(y_i-\overline{y})^2}{n-3}
\mbox{ for }n>3
\end{array} \]

\end{frame}



\begin{frame}
\frametitle{Focusing on $\mu$}

Typically, the main quantity of interest in the normal model is the mean, $\mu$.
\pause
Thus, we are typically interested in the marginal posterior for $\mu$:
\pause
\[
p(\mu|y) = \pause \int p(\mu|\sigma^2,y)p(\sigma^2|y) d\sigma^2.
\]
\pause
If
\[
\mu|\sigma^2,y \sim N(\overline{y}, \sigma^2/n) \quad \mbox{and} \quad
\sigma^2|y \sim IG\left(\frac{n-1}{2}, \frac{\sum_{i=1}^n(y_i-\overline{y})^2}{2}\right),
\]
then
\[
\mu|y \sim t_{n-1}(\overline{y}, s^2/n) \quad \mbox{where} \quad
s^2 = \frac{1}{n-1}\sum_{i=1}^n (y_i-\overline{y})^2
\]
\pause
that is, $\mu|y$ has a $t$ distribution with $n-1$ degrees of freedom, location
parameter $\overline{y}$ and scale parameter $s^2/n$.

\end{frame}



\begin{frame}
\frametitle{$t$ distribution}

\begin{definition}
A $t$ distributed random variable, $T\sim t_v(m,s^2)$ has probability density function
\[ f_T(t) = \frac{\mathrm{\Gamma}([v+1]/2)}{\mathrm{\Gamma}(v/2)\sqrt{v\pi}s}\left(1+\frac{1}{v}\left[\frac{x-m}{s}\right]^2\right)^{-(v+1)/2} \]
\pause
with degrees of freedom $v$, location $m$, and scale $s^2$.
\pause
It has
\[ \begin{array}{rll}
E[T] &= m & v>1 \\
Var[T] &= s^2 \frac{v}{v-2} & v>2.
\end{array} \]
\pause
In addition,
\[
t_v(m,s^2) \stackrel{d}{\to} N(m,s^2) \quad \mbox{as} \quad
v\to\infty.
\]

\end{definition}

\end{frame}



\begin{frame}[fragile]
\frametitle{$t$ distribution as $v$ changes}
<<t_distribution, fig.height=4.5, warning=FALSE>>=
dtms = function(x,v,m=0,s=1) dt((x-m)/s,v)/s

d = expand.grid(v=10^(0:2), t = seq(-3,6,by=.1)) %>%
  mutate(density = dtms(t,v),
         v = factor(v))

ggplot(d, aes(x=t,y=density, group=v, linetype=v, color=v)) +
  geom_line() +
  theme(legend.position='bottom') +
  theme_bw()
@
\end{frame}


\begin{frame}[fragile]
\frametitle{Credible intervals}

In R, there is no way to obtain $t$ credible intervals directly.
\pause
Thus we can use the fact that
\[
\frac{\mu-\overline{y}}{s/\sqrt{n}} \pause \sim t_{n-1}(0,1)
\]
to construct the interval using
\[
\overline{y} \pm t_{n-1,a/2} s/\sqrt{n}
\]
where the area to the right of $t_{n-1,a/2}$ under the pdf of a
standard $t$ is $a/2$.

\pause

<<mu_ci, dependson="data", echo=TRUE>>=
mean(y) + c(-1,1)*qt(.975, df=n-1)*sd(y)/sqrt(n)
@

\end{frame}


\begin{frame}[fragile]
\frametitle{Corn yield}

\small

In evaluating corn yield for a particular year,
the yield on a number of fields is measured. \pause
(For simplicity, assume that fields are standardized in size.)
\pause
We measure $\Sexpr{n}$ randomly selected fields in Iowa and
find the sample average is \Sexpr{round(mean(y))} bushels per acre and the
sample standard deviation is \Sexpr{round(sd(y))} bushels per acre.
\pause
Provide a 90\% credible interval for the mean yield across all fields in Iowa.

\vspace{0.1in} \pause

Let $Y_i$ be the yield in field $i$ and assume
\[
Y_i\ind N(\mu,\sigma^2).
\]
If we assume the default prior $p(\mu,\sigma^2)\propto 1/\sigma^2$, then we have
\[
\mu|y \sim t_{n-1}(\overline{y},s^2/n).
\]
\pause
A 90\% interval is
<<credible_interval, echo=TRUE>>=
a    <- 0.1

mean(y) +c(-1,1)*qt(1-a/2, df=n-1)*sd(y)/sqrt(n)
@
\end{frame}



% % \begin{frame}[fragile]
% % \frametitle{Analysis in R}
% % 
% % \small
% % 
% % There is no reason that you need to do this all yourself. 
% % In R, the function {\tt t.test} will provide you with the relevant information.
% % 
% % <<echo=TRUE>>=
% % t <- t.test(y, conf.level = 1-a)
% % t$parameter # n-1 (degrees of freedom)
% % t$estimate  # Mean
% % t$conf.int  # Credible interval
% % @
% % 
% % \end{frame}


\subsection{Informative Bayesian analysis}
\begin{frame}[fragile]
\frametitle{Informative Bayesian analysis when pop. variance is known}

\small

Let $Y_i$ be the corn yield (in bushels/ac) from field $i$.
Assume
\[
Y_i \ind N(\mu,v^2) \quad \mbox{and} \quad
\mu \sim N(m,C)
\]
where $m$ provides your prior guess about the mean yield 
(not the population mean as was used previously in this slide set) 
and $C$ provides your variance around that guess.
\pause
Then
\[ \begin{array}{rl}
\mu|y &\sim N(m',C') \pause \\
C' &= \left[ \frac{1}{C} + \frac{n}{v^2} \right]^{-1} \pause \\
m' &= C' \left[ \frac{1}{C}m + \frac{n}{v^2}\overline{y} \right] \pause
= \frac{1/C}{1/C+n/v^2} m + \frac{n/v^2}{1/C+n/v^2}\overline{y}
\end{array} \]
\pause
<<prior, echo=TRUE>>=
m = 200; C = 10^2
@
<<posterior, echo=TRUE, dependson="prior">>=
Cp = 1/(1/C+n/v^2); mp = Cp*(m/C+n*mean(y)/v^2)
@
So if we assume $m=200$ and $C=\Sexpr{sqrt(C)}^2$ and combine this with our observed data
$n=$\Sexpr{length(y)} and $\overline{y}=$\Sexpr{round(mean(y))} with 
population sd known to be $v=$\Sexpr{v},
\pause
then we have the posterior $\mu|y\sim N(\Sexpr{round(mp)},\Sexpr{round(sqrt(Cp))}^2)$.
\end{frame}


\begin{frame}[fragile]
\frametitle{Comparison of default vs informative Bayesian analysis}

\vspace{-0.1in}

<<echo=TRUE, fig.height=3.5, dependson=c("prior","data","population_parameters")>>=
ybar = mean(y); se = v/sqrt(n)
curve(dnorm(x, mean=ybar, sd=se), ybar-3*se, ybar+3*se,
      ylim=c(0,.1),
      xlab=expression(mu),
      ylab=expression(paste("p(",mu,"|y)")),
      main="Default vs informative Bayesian analysis")
curve(dnorm(x, mean=mp, sd=sqrt(Cp)), col='red', lty=2, add=TRUE)
legend("topleft", c("Default","Informative"), col=c("black","red"),
       lty = 1:2)
@

\end{frame}



\begin{frame}
\frametitle{Informative Bayesian analysis}
  The joint conjugate prior for $\mu$ and $\sigma^2$ is
  \[ \mu|\sigma^2\phantom{,y} \sim N(m,\sigma^2/k) \qquad \sigma^2\phantom{,y} \sim IG(d/2,dv^2/2) \]
  \pause where $v^2$ serves as a prior guess about $\sigma^2$ and $d$ controls how certain we are about that guess.

  \vspace{0.2in} \pause

  The posterior under this prior is
  \[ \mu|\sigma^2,y \sim N(m',\sigma^2/k') \qquad \sigma^2|y \sim IG(d'/2,d'(v')^2/2) \]
  \pause where
  \[ \begin{array}{rl}
  k' &= k+n \\
  m' &= [km + n\overline{y}]/k' \\
  d' &= d+n \\
  d'(v')^2 &= dv^2 + (n-1)s^2 + \frac{kn}{k'}(\overline{y}-m)^2
  \end{array} \]
\end{frame}




\end{document}
