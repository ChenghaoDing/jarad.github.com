\documentclass[handout]{beamer}

\input{../frontmatter}
\input{../commands}

\newtheorem{principle}[theorem]{Principle}

\title{Set07 - Statistics}

\begin{document}


<<options, results='hide', echo=FALSE, purl=FALSE>>=
opts_chunk$set(comment=NA, 
               fig.width=6, fig.height=5, 
               size='tiny', 
               out.width='0.8\\textwidth', 
               fig.align='center', 
               message=FALSE,
               echo=FALSE,
               cache=TRUE)
options(width=120)
@

<<libraries, message=FALSE, warning=FALSE, cache=FALSE>>=
library(dplyr)
library(ggplot2)
library(gridExtra)
@

<<set_seed>>=
set.seed(2)
@


\begin{frame}
\maketitle
\end{frame}


\section{Descriptive statistics}
\begin{frame}
\frametitle{Statistics}
\begin{definition}
The \alert{field of statistics} is the study of the collection, analysis, interpretation, 
presentation, and organization of data.

{\tiny \url{https://en.wikipedia.org/wiki/Statistics}}
\end{definition}

\vspace{0.1in} \pause

There are two different phases of statistics: \pause
\begin{itemize}
\item descriptive statistics \pause 
	\begin{itemize}
	\item statistics
	\item graphical statistics
	\end{itemize}
\item inferential statistics.
\end{itemize}

\end{frame}




\subsection{Sample}
\begin{frame}
\frametitle{Population and sample}
\begin{definition}
The \alert{population} consists of all units of interest. \pause 
Any numerical characteristic of a population is a \alert{parameter}. \pause
The \alert{sample} consists of observed units collected from the population. 
\pause
Any function of a sample is called a \alert{statistic}.
\end{definition}

\vspace{0.1in} \pause

\begin{example}

Consider the population of all in-use routers by undergraduate students 
at Iowa State University. \pause
We are interested in what proportion have Gigabit speed. \pause
We collect data from students in STAT 401 (our sample) and record the 
proportion (a statistic) that have Gigabit routers. 
\end{example}
\end{frame}



\subsection{Random sample}
\begin{frame}
\frametitle{Simple random sampling}
\begin{definition}
A \alert{simple random sample} is a sample from the population where all subsets
of the same size are equally likely to be sampled. \pause
Simple random samples ensure that statistical conclusions will be valid.
\end{definition}

\vspace{0.1in} \pause 

\begin{example}
Consider the population of all in-use routers by undergraduate students 
at Iowa State University. \pause
We are interested in what proportion have Gigabit speed. \pause
A pseudo-random number generator gives each student a Unif(0,1) number and the
lowest 100 are contacted (our sample) and the proportion (a statistic) of these 
students who have Gigabit routers is recorded.
\end{example}
\end{frame}


\begin{frame}
\frametitle{Sampling and non-sampling errors}

\begin{definition}
\alert{Sampling errors} are caused by the mere fact that only a sample, a 
portion of a population, is observed.
\pause 
For most reasonable statistical procedures, sampling errors decrease (and 
converge to zero) as the sample size increases.

\vspace{0.1in} \pause

\alert{Non-sampling errors} are caused by inappropriate sampling schemes and
wrong statistical techniques. \pause 
Often, no statistical technique can rescue a poorly collected sample of data. 
\end{definition}

\pause
\begin{example}
In our example, no statistical technique can help us estimate
the proportion of students at ISU who have Gigabit routers based on our 
convenience sample of STAT 401 students who have a Gigabit router.
\end{example}

\end{frame}


\subsection{Statistics}
\begin{frame}
\frametitle{Descriptive statistics}
\begin{definition}
A \alert{statistic} is any function of the data. 
\end{definition}

\pause

\begin{example}
Statistics:
\begin{itemize}
\item Sample mean
\item Sample median
\item Sample mode
\item Sample quantile
\item Sample variance
\item Sample standard deviation
\end{itemize}
\end{example}

\pause

Most statistics are developed to estimate the corresponding population 
parameter.

\end{frame}



\subsection{Mean and variance}
\begin{frame}
\frametitle{Sample mean}

Let $X_1,\ldots,X_n$ be a sample from a distribution with 
\[ E[X_i] = \mu \qquad \mbox{ and } \qquad Var[X_i] = \sigma^2 \] 
where we assume independence between the $X_i$. 

\vspace{0.1in} \pause

The sample mean is 
\[ 
\overline{X} = \frac{1}{n} \sum_{i=1}^n X_i
\]
\pause
and estimates the population mean $\mu$. 

\vspace{0.1in} \pause

The sample variance is 
\[ 
S^2 = \frac{1}{n-1} \sum_{i=1}^n (X_i-\overline{X})^2 
= \frac{\sum_{i=1}^n X_i^2 - n\overline{X}^2}{n-1}
\]
and estimates the population variance $\sigma^2$. \pause 
The sample standard deviation  is $S = \sqrt{S^2}$.

\end{frame}



\subsection{Unbiased}
\begin{frame}
\frametitle{Unbiased}

\begin{definition}
An estimator is \alert{unbiased} for a parameter if its expectation equals the
parameter. 
\end{definition}

\pause

\begin{example}
The sample mean is unbiased for $\mu$ since
\[ 
E\left[\,\overline{X}\,\right] = E\left[\frac{1}{n} \sum_{i=1}^n X_i \right]
= \frac{1}{n} \sum_{i=1}^n E[X_i] = \mu.
\]
and the sample variance is unbiased for $\sigma^2$.
\end{example}
\end{frame}



\subsection{Consistent}
\begin{frame}
\frametitle{Consistent}

\begin{definition}
An estimator $\hat{\theta}$, or $\hat{\theta}(x)$, is \alert{consistent} for a parameter $\theta$ if 
the probability of its sampling error of any magnitude converges to 0 as the
sample size increases to infinity, \pause i.e.
\[ 
P\left( |\hat{\theta}(x)-\theta|>\epsilon \right) \to 0 \mbox{ as } n\to\infty
\]
for any $\epsilon>0$.
\end{definition}

\pause 

\begin{example}
The sample mean is consistent for $\mu$ since $Var[\overline{X}] = \sigma^2/n$
and 
\[ 
P\left(|\overline{X} - \mu| > \epsilon \right) \le 
\frac{Var[\overline{X}]}{\epsilon^2} = \frac{\sigma^2/n}{\epsilon^2} \to 0
\]
where the inequality is from Chevyshev's inequality on pg 54 of Baron. 
\end{example}
\end{frame}



\subsection{Quantiles}
\begin{frame}
\frametitle{Quantiles}
\begin{definition}
A \alert{$p$-quantile} of a population is such a number $x$ that solves
\[ 
P(X<x) \le p \quad \mbox{and} \quad P(X>x) \le 1-p.
\]
\pause
A \alert{sample $p$-quantile} is any number that exceeds at most $100p$\% of the
smample, and is exceeded by at most $100(1-p)$\% of the sample.  \pause
A \alert{$100p$-percentile} is a $p$-quantile. 
\pause
First, second, and third \alert{quartiles} are the 25th, 50th, and 75th 
percentiles. 
They split a population or a sample into four equal parts.
\pause
A \alert{median} is a 0.5-quantile, 50th percentile, and 2nd quartile.
\pause
The \alert{interquartile range} is the third quartile minus the first quartile,
i.e.
\[ 
IQR = Q_3 - Q_1
\]
and the \alert{sample interquartile range} is the third sample quartile minus
the first sample quartile, i.e.
\[ 
\hat{IQR} = \hat{Q}_3 - \hat{Q}_1
\]
\end{definition}
\end{frame}



\begin{frame}[fragile]
\frametitle{Standard normal quartiles}
<<quantiles, fig.height=4, echo=TRUE>>=
curve(expr = dnorm, from = -3, to = 3, ylab = "f(x)")
quantiles = c(.25,.50,.75)
abline(v = qnorm(p = c(.25,.50,.75))) # default is standard normal
@
\end{frame}




\begin{frame}[fragile]
\frametitle{Sample quartiles from a standard normal}
<<sample_quantiles, dependson='quantiles', fig.height=4, echo=TRUE>>=
n = 1000
sample = rnorm(n)
hist(x = sample, breaks = 101, probability = TRUE, border = "gray", col = "gray")
curve(expr = dnorm, from = -3, to = 3, ylab = "f(x)", col = "black", add = TRUE)
abline(v = qnorm(p = quantiles), col = "black")
abline(v = quantile(sample, prob = quantiles), col = "gray")
legend("topright", c("sample","population"), lty=1, col=c("gray","black"))
@
\end{frame}



\subsection{Standard error}
\begin{frame}
\frametitle{Standard error}
\begin{definition}
The \alert{standard error} of a statistic $\hat{\theta}$ is the standard
deviation of that statistic (when the data are considered random).
\end{definition}
\pause
\begin{example}
The standard error of the sample mean is $\sigma/\sqrt{n}$ since (if the $X_i$
are independent) we have
\[
Var[\overline{X}] = Var\left[ \frac{1}{n} \sum_{i=1}^n X_i \right] =
\frac{1}{n^2} \sum_{i=1}^n Var[X_i] = \frac{1}{n^2} \sum_{i=1}^n \sigma^2 =
\sigma^2/n
\]
\pause
and thus
\[
SD[\overline{X}] = \sqrt{Var[\overline{X}]} = \sigma/\sqrt{n}.
\]
\end{example}
\end{frame}




\subsection{Binomial example}
\begin{frame}
\frametitle{Server uptime}
\small

We are interested in the random variable $X\sim Ber(\theta)$ with
$\theta\in(0,1)$ that represents whether or not a server is up. 
\pause
At random times and sufficiently far apart that we can reasonably assume
independence, we ping the server to determine whether it is responding. 
\pause
\begin{itemize}
\item The population here is the server status across all times and the relevant 
population quantity is $\theta$, the proportion of time the server is up. 
\pause
\item The sample $X_i \stackrel{ind}{\sim} Ber(\theta)$ are the server status when
you pinged the server. \pause From the description, it isn't entirely clear 
whether or not this can be viewed as a simple random sample. 
\item The sample mean is an estimator of the population mean, i.e. 
\[
\hat{\theta} = \frac{1}{n} \sum_{i=1}^n X_i
\]
and it is unbiased and consistent \pause since
\[ 
E[\hat{\theta}] = \theta \quad \mbox{and} \quad
Var[\hat{\theta}] = \theta(1-\theta)/n. 
\]
\end{itemize}

\end{frame}


\subsection{Summary}
\begin{frame}
\frametitle{Summary}
\begin{itemize}
\item Statistics are functions of data.
\item Statistics have some properties:
	\begin{itemize}
	\item Standard error
	\end{itemize}
\item Statistics often try to estimate population parameters and are then called
estimators.
\item Estimators may have these properties relative to the population parameter
they are trying to estimate:
\begin{itemize}
\item Unbiased
\item Consistent 
\end{itemize}
\end{itemize}

\end{frame}





\section{Graphical statistics}
\begin{frame}
\frametitle{Look at it!}
{\Huge
\alert{Before you do anything with a data set, \pause LOOK AT IT!}
}
\end{frame}



\begin{frame}
\frametitle{Why should you look at your data?}

\pause

\begin{enumerate}
\item Find errors \pause
	\begin{itemize}
	\item Do variables have the correct range, e.g. positive?
	\item How are Not Available encoded?
	\item Are there outliers? \pause
	\end{itemize}
\item Do known or suspected relationships exist? \pause
	\begin{itemize}
	\item Is X linearly associated with Y?
	\item Is X quadratically associated with Y? \pause
	\end{itemize}
\item Are there new relationships? \pause
	\begin{itemize}
	\item What is associated with X and how? \pause
	\end{itemize}
\item Do variables adhere to distributional assumptions? \pause
	\begin{itemize}
	\item Does X have an approximately normal distribution?
	\item Right/left skew
	\item Heavy tails
	\end{itemize}
\end{enumerate}
\end{frame}






\begin{frame}[fragile]
\frametitle{Backblaze Hard drive failure data}

\url{https://ucr.fbi.gov/crime-in-the-u.s/2013/crime-in-the-u.s.-2013/tables/1tabledatadecoverviewpdf/table_1_crime_in_the_united_states_by_volume_and_rate_per_100000_inhabitants_1994-2013.xls}

<<harddrive_data>>=
d <- readxl::read_excel("crime.xls") %>%
  mutate(capacity = capacity_bytes * 1e-12) %>%
  select(model, serial_number, capacity, failure)
summary(d)
@
\end{frame}



\begin{frame}[fragile]
\frametitle{Histogram}
<<histogram, dependson="harddrive_data">>=
ggplot(d, aes(x = capacity)) + 
  geom_histogram(binwidth=.5) + 
  labs(title = "Hard drive capacity (TB)") +
  theme_bw()
@
\end{frame}



\begin{frame}[fragile]
\frametitle{Histogram}
<<histogram_density, dependson="harddrive_data">>=
ggplot(d, aes(x = capacity)) + 
  geom_histogram(aes(y=..density..), binwidth=1) + 
  labs(title = "Hard drive capacity (TB)") +
  theme_bw()
@
\end{frame}


\begin{frame}[fragile]
\frametitle{Histogram}
<<histogram_facet, dependson="harddrive_data">>=
ggplot(d, aes(x = capacity)) + 
  geom_histogram(binwidth=1) + 
  facet_wrap(~failure) +
  labs(title = "Hard drive capacity (TB)") +
  theme_bw()
@
\end{frame}


\subsection{Boxplot}
\begin{frame}[fragile]
\frametitle{Boxplot}
<<boxplot_facet, dependson="harddrive_data">>=
ggplot(d, aes(x = section, y = exam2)) + geom_boxplot()
@
\end{frame}



\begin{frame}
\frametitle{Boxplot lines}

By default in {\tt ggplot}, a boxplot will produce
\begin{itemize}
\item A box for the 1st and 3rd quartiles \pause with
\item a line in the ``middle'' for the median \pause and 
\item whiskers extending to the largest/smallest values within 1.5IQR, \pause and
\item dots for data points farther out than that, i.e. ``outliers''. 
\end{itemize}

\vspace{0.1in} \pause

There is no standard for boxplots, so be careful in interpreting a boxplot 
unless you know how it is constructed. 

\end{frame}




\subsection{Scatter plots}
\begin{frame}
\frametitle{Scatter plots}
When there are two continuous variables to plot at the same time, 
use a scatter plot. 
\pause
The variable you believe would predict the other variable, should go on the 
x-axis.
\end{frame}



\begin{frame}[fragile]
\frametitle{Exam 2 vs homework subtotal}
<<exam2_v_homework, dependson="harddrive_data">>=
ggplot(d %>% filter(exam2>0, homework>0), aes(x = homework, y = exam2)) + 
	geom_point()
@
\end{frame}



\begin{frame}[fragile]
\frametitle{Exam 2 vs homework subtotal}
<<exam2_v_homework_reg, dependson="harddrive_data">>=
ggplot(d %>% filter(exam2>0, homework>0), aes(x = homework, y = exam2)) + 
	geom_point() + geom_smooth(method='lm',formula=y~x)
@
\end{frame}


\begin{frame}[fragile]
\frametitle{Exam 2 vs Exam 1 subtotal}
<<exam2_v_exam1, dependson="harddrive_data">>=
ggplot(d %>% filter(exam2>0, exam1>0), aes(x = exam1, y = exam2)) + 
	geom_point()
@
\end{frame}

\begin{frame}[fragile]
\frametitle{Exam 2 vs Exam 1 subtotal}
<<exam2_v_exam1_reg, dependson="harddrive_data">>=
ggplot(d %>% filter(exam2>0, exam1>0), aes(x = exam1, y = exam2)) + 
	geom_point() + geom_smooth(method='lm',formula=y~x)
@
\end{frame}

\begin{frame}[fragile]
\frametitle{Exam 2 vs Exam 1 subtotal}
<<exam2_v_exam1_scatter, dependson="harddrive_data">>=
ggplot(d %>% filter(exam2>0, exam1>0), aes(x = exam1, y = exam2)) + 
	geom_jitter()
@
\end{frame}


\subsection{All-in-one plots}
\begin{frame}
\frametitle{All-in-one plots}
<<>>=
GGally::ggpairs(d)
@
\end{frame}



\subsection{Two-dimensional histograms}
\begin{frame}[fragile]
\frametitle{Two-dimensional histograms}

Sometimes there are so many points that you cannot see a relationship in a 
scatterplot, \pause e.g. 
<<bigdata>>=
n = 1e4; r = runif(n, 0, 2*pi)
normal = data.frame(x = rnorm(2*n), y = rnorm(2*n))
circle = data.frame(x = sin(r)/2, y = cos(r)/2)
big_data = bind_rows(normal,circle)
ggplot(big_data, aes(x,y)) + geom_point()
@
\end{frame}


\begin{frame}[fragile]
\frametitle{Hexbin plot}

<<hexbin, dependson="bigdata">>=
ggplot(big_data, aes(x,y)) + stat_binhex()
@

\end{frame}


\begin{frame}
\frametitle{Principles of professional statistical graphics}

\begin{itemize}
\item Show the data
	\begin{itemize}
	\item Avoid distorting the data, e.g. pie charts, 3d pie charts, exploding wedge 3d pie charts, bar charts that do not start at zero
	\end{itemize}
\item Plots should be self-explanatory
	\begin{itemize}
	\item Use informative caption, legend
	\item Use normative colors, shapes, etc
	\end{itemize}
\item Have a high information to ink ratio
	\begin{itemize}
	\item Avoid bar charts
	\end{itemize}
\item Encourage eyes to compare
	\begin{itemize}
	\item Use size, shape, and color to highlight differences
	\end{itemize}
\end{itemize}

{\tiny \url{https://moz.com/blog/data-visualization-principles-lessons-from-tufte}}

\end{frame}


\begin{frame}
\frametitle{Stock market return}
\begin{center}
\includegraphics{triangle}
\end{center}
{\tiny \url{http://www.nytimes.com/interactive/2011/01/02/business/20110102-metrics-graphic.html?_r=0}}
\end{frame}
 



\end{document}



