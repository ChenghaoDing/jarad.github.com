\documentclass[handout]{beamer}

\usepackage{verbatim,multicol,amsmath}

\input{../frontmatter}
\input{../commands}

\title{Set 12 - Confidence intervals}

% \newenvironment{remark}[1][Remark]{\begin{trivlist}
% \item[\hskip \labelsep {\bfseries #1}]}{\end{trivlist}}

<<options, results='hide', echo=FALSE, purl=FALSE>>=
opts_chunk$set(comment=NA, 
               fig.width=6, fig.height=5, 
               size='tiny', 
               out.width='0.8\\textwidth', 
               fig.align='center', 
               message=FALSE,
               echo=FALSE)
options(width=120)
@

<<libraries, message=FALSE, warning=FALSE>>=
library(plyr)
library(dplyr)
library(tidyr)
library(ggplot2)
@

<<set_seed, echo=FALSE>>=
set.seed(2)
@

\begin{document}

\begin{frame}
\maketitle
\end{frame}


\section{Confidence intervals}
\begin{frame}
\frametitle{Confidence intervals}

\begin{definition}
The \alert{coverage} of an interval estimator is the probability the interval 
will contain the true value of the parameter 
\emph{when the data are considered to be random}.
\pause
If an interval estimator has $100(1-a)\%$ coverage, 
then we call it a $100(1-a)\%$ \alert{confidence interval}
\pause
and $1-a$ is the \alert{confidence level}.
\end{definition}

\end{frame}


\begin{frame}
\frametitle{Normal model}

If $Y_i \ind N(\mu,\sigma^2)$ and we assume the default prior 
$p(\mu,\sigma^2) \propto 1/\sigma^2$, 
\pause 
then a $100(1-a)\%$ credible interval for $\mu$ 
\pause 
is given by 
\[ 
\overline{y} \pm t_{n-1,a/2}s/\sqrt{n}.
\]
\pause
When the data are considered random
\[ 
T = \frac{\overline{Y}-\mu}{S/\sqrt{n}} \sim t_{n-1} \sim t_{n-1}(0,1)
\]
\pause
thus the probability $\mu$ is within our credible interval is
\[ \begin{array}{rl}
\multicolumn{2}{l}{P\left( \overline{Y}-t_{n-1,a/2}S/\sqrt{n} < \mu < \overline{Y}-t_{n-1,a/2}S/\sqrt{n}\right)} \pause \\
&= P\left( -t_{n-1,a/2} < \frac{\overline{Y}-\mu}{S/\sqrt{n}} < t_{n-1,a/2}\right) \pause \\
&= P\left( -t_{n-1,a/2} < T < t_{n-1,a/2}\right) \pause \\
&= 1-a.
\end{array} \]
\pause
Thus, this $100(1-a)\%$ credible interval is also a $100(1-a)\%$ confidence interval.
\end{frame}


\begin{frame}
\frametitle{Data example}
<<echo = FALSE, fig.height=4>>=
y <- rnorm(9, mean = 200, sd = 20)
n <- length(y)
ybar <- mean(y)
s <- sd(y)
a <- .05
t_crit <- qt(a/2, df = n-1)
L <- ybar - t_crit*s/sqrt(n)
U <- ybar + t_crit*s/sqrt(n)
@

Recall the corn yield example from Set 11 with $\Sexpr{n}$ randomly selected 
fields in Iowa whose 
sample average yield is $\Sexpr{round(ybar)}$ and sample standard 
deviation is $\Sexpr{round(s)}$. 
\pause
Then a $\Sexpr{100*(1-a)}\%$ confidence interval for the is 
\[
\Sexpr{round(ybar)}\pm \Sexpr{round(t_crit,2)}\times \Sexpr{round(s)}/\sqrt{\Sexpr{n}}
= (\Sexpr{round(L)},\Sexpr{round(U)}).
\]
\pause
This confidence interval tells us nothing about the true mean yield of fields 
in Iowa.
\pause
Instead, it tells us that if we use this \alert{procedure} repeatedly on 
different data sets, then $\Sexpr{100*(1-a)}\%$ of the time, the interval
will contain the true parameter.
\end{frame}



\subsection{Approximate confidence intervals}
\begin{frame}
\frametitle{Sampling distribution}

\begin{definition}
The \alert{sampling distribution} of a statistic is the distribution of the 
statistic \emph{when the data are considered random}.
\end{definition}

\pause

\begin{example}
If $Y_i \ind N(\mu,\sigma^2)$, then 
\[ 
T = \frac{\overline{Y}-\mu}{S/\sqrt{n}} \sim t_{n-1}(0,1)
\]
where $\overline{Y}$ and $S$ are the sample average and sample standard 
deviation over $n$ observations.
\end{example}

\pause

Most of the time we don't know the sampling distribution of the statistic.


\end{frame}




\begin{frame}
\frametitle{Approximate sampling distributions}

If the estimator $\hat\theta=\hat\theta(Y)$ is based on an average or a sum, 
then the Central Limit Theorem tells us what its \alert{approximate} sampling
distribution is, \pause i.e.
\[ 
\hat\theta \stackrel{\cdot}{\sim} N(E[\hat{\theta}], Var[\hat{\theta}]).
\]

\pause

\begin{example}
If $Y_i \ind N(\mu,\sigma^2)$, then 
\[ 
\hat{\theta} = \overline{Y} \pause 
\stackrel{\cdot}{\sim} N(E[\overline{Y}], Var[\overline{Y}])
\]
\pause
where 
\[ \begin{array}{rl}
E[\overline{Y}] &= \mu \\
Var[\overline{Y}] \pause &= \sigma^2/n.
\end{array} \]
\end{example}
\end{frame}


\begin{frame}
\frametitle{Standard error}

\small

\begin{definition}
The \alert{standard error} of an estimator is an \emph{estimate} of the standard
deviation of the sampling distribution of the estimator.
\end{definition}

\pause

\begin{example}
If $Y_i \ind N(\mu,\sigma^2)$ and $\hat\theta = \overline{Y}$, \pause
then
\[
Var[\hat\theta] = Var[\overline{Y}] =
\pause
\sigma^2/n
\quad
\mbox{and}
\quad
\sqrt{Var[\hat\theta]} = \sigma/\sqrt{n}.
\]
\pause
We have the following \emph{consistent} estimators
\[ 
S^2 \stackrel{P}{\to} \sigma^2, \quad \pause
S \stackrel{P}{\to} \sigma, \quad 
\mbox{and}
\quad\pause
S/\sqrt{n} \stackrel{P}{\to} \sigma/\sqrt{n}
\]
\pause
and thus 
\[
SE[\hat\theta] = \widehat{\sqrt{Var[\hat\theta]}} = S/\sqrt{n}.
\]
where $S$ is the sample standard deviation.
\end{example}
\end{frame}



\begin{frame}
\frametitle{Approximate confidence intervals}

If an estimator has an asymptotic normal distribution, 
then we can construct an \alert{approximate} $100(1-a)$\% confidence interval
for $E[\hat\theta]$ using 
\[ 
\hat{\theta} \pm z_{a/2} SE[\hat\theta].
\]
where $SE(\hat\theta)=\sqrt{Var[\hat\theta]}$ is the \alert{standard error} of 
the estimator.

\vspace{0.1in} \pause

This comes from the fact that if 
$\hat\theta \stackrel{\cdot}{\sim} N(E[\hat\theta],Var[\hat\theta])$, \pause then
\[ \begin{array}{rl}
\multicolumn{2}{l}{P\left( \hat{\theta} - z_{a/2} SE(\hat\theta) < E[\hat\theta] < \hat\theta \pm z_{a/2} SE(\hat\theta) \right)} \pause \\
&= P\left( -z_{a/2} < \frac{\hat\theta-E[\hat\theta]}{SE(\hat\theta)} < z_{a/2} \right) \pause \\
&= P\left( -z_{a/2} < \frac{\hat\theta-E[\hat\theta]}{\sqrt{Var[\hat\theta]}} < z_{a/2} \right) \pause \\
&\approx P\left( -z_{a/2} < Z < z_{a/2} \right) \pause \\
&= 1-a.
\end{array} \]


\end{frame}


\begin{frame}
\frametitle{Normal example}

If $Y_i \ind N(\mu,\sigma^2)$ and we have the estimator 
$\hat\theta = \overline{Y}$, then 
\[ \begin{array}{rl} 
E[\hat\theta] &= \mu \\
SE[\hat\theta] &= S/\sqrt{n}
\end{array} \]

\pause

Thus an \alert{approximate} $100(1-a)$\% confidence interval
for $\mu=E[\hat\theta]$ is 
\[ 
\overline{Y} \pm z_{a/2} SE[\hat\theta] = \overline{Y} \pm z_{a/2} S/\sqrt{n}.
\]
\pause
Note that this is almost identical to the \alert{exact} $100(1-a)$\%  
confidence interval for $\mu$, 
\[ 
\overline{Y} \pm t_{n-1,a/2} S/\sqrt{n}
\]
\pause
and when $n$ is large $z_{a/2} \approx t_{n-1,a/2}$.
\end{frame}




\begin{frame}
\frametitle{T critical values vs Z critical values}

<<fig.height=4>>=
d <- expand.grid(n = 10^(1:3), a = 1-c(.9,.95,.99)) %>%
  group_by(n, a) %>%
  mutate(z_crit = qnorm(1-a/2),
         t_crit = qt(   1-a/2, df=n-1)) %>%
  ungroup() %>%
  mutate(n = as.factor(n))

ggplot(d, aes(z_crit, t_crit, group=n, linetype=n, color=n)) +
  geom_line() +
  geom_abline(intercept = 0, slope = 1, color='gray') +
  coord_fixed() +
  theme_bw() 
@

\end{frame}




\subsection{Binomial example}
\begin{frame}
\frametitle{Binomial example}

Suppose $Y\sim Bin(n,\theta)$ and we are interested in a confidence interval 
for $\theta$. \pause
An estimator for $\theta$ is 
\[ 
\hat\theta = \frac{Y}{n}
\]
since $E[\hat\theta] = \theta$. 
\pause
The variance when the data are considered random of this estimator is 
\[
Var[\hat\theta] = \frac{\theta(1-\theta)}{n}.
\]
\pause
A standard error for this estimator is 
\[ 
SE[\hat\theta] = \sqrt{\frac{\hat\theta (1-\hat\theta)}{n}}
\]
since $\hat\theta = Y/n$ is a consistent estimator for $\theta$

\end{frame}


\begin{frame}
\frametitle{Approximate confidence interval for binomial proportion}

\small

If $Y\sim Bin(n,\theta)$, then an approximate $100(1-a)$\% confidence interval
for $\theta$ is 
\[ 
\hat\theta \pm z_{a/2} \sqrt{\frac{\hat\theta (1-\hat\theta)}{n}}.
\]
\pause 
where $\hat\theta = Y/n$.

\pause

\begin{example}
The Gallup poll is a poll of approximately 1,500 (randomly selected?) U.S. 
adults. 
\pause
In the post recent poll (2017/02/19), 32.1\% of respondents indicated that they
were engaged at work. 
\pause
Thus an approximate 95\% confidence interval for the proportion of all U.S. 
adults is 
\[ 
0.321 \pm 1.96 \times \sqrt{\frac{.321(1-.321)}{1500}} = (0.30, 0.34).
\]
\pause
But the confidence interval actually says nothing about where the true 
proportion is. \pause
Instead it says something about how many of our intervals would cover the truth
if we were to repeat this procedure over and over.
\end{example}



\end{frame}



\end{document}



