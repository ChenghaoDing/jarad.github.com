\documentclass[handout]{beamer}

\usepackage{verbatim,multicol,amsmath}

% Theme settings
\usetheme{AnnArbor}\usecolortheme{beaver}
\setbeamertemplate{navigation symbols}{}


% Document settings
\newcommand{\lecturetitle}{Simple linear regression}
\title[\lecturetitle]{STAT 401A - Statistical Methods for Research Workers}
\subtitle{\lecturetitle}
\author[Jarad Niemi]{Jarad Niemi (Dr. J)}
\institute[Iowa State]{Iowa State University}
\date[\today]{last updated: \today}


\setkeys{Gin}{width=0.6\textwidth}
\newenvironment{remark}[1][Remark]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}]}{\end{trivlist}}

<<options, echo=FALSE, warning=FALSE, message=FALSE>>=
opts_chunk$set(comment=NA, fig.width=6, fig.height=5, size='tiny', out.width='0.6\\textwidth', fig.align='center', message=FALSE)
library(plyr)
library(ggplot2)
library(xtable)
library(Sleuth3)
library(abd)
@


\begin{document}



\begin{frame}
\maketitle
\end{frame}


\section{Model}
\frame{\frametitle{Simple Linear Regression}
  Recall the one-way ANOVA model:
	\[ Y_{ij} \stackrel{ind}{\sim} N(\mu_j,\sigma^2) \]
	where $Y_{ij}$ is the observation for individual $i$ in group $j$.
	
	\vspace{0.2in}  \pause
	
	The \alert{simple linear regression} model is 
	\[ Y_i \stackrel{ind}{\sim} N(\beta_0+\beta_1 X_i, \sigma^2) \]
	where $Y_i$ and $X_i$ are the response and explanatory variable, respectively, for individual $i$.
	
	\pause
	
	Terminology (all of these are equivalent):
	\begin{tabular}{ll}
	\hline
	response & explanatory \\
	outcome & covariate \\
	dependent & independent \\
	endogenous & exogenous \\
	\hline
	\end{tabular}
}

\begin{frame}[fragile]
\frametitle{}
<<echo=FALSE>>=
data(Telomeres)
ggplot(Telomeres, aes(x=years, y=telomere.length))+geom_point()+geom_smooth(method='lm', se=FALSE)
@
\end{frame}


\begin{frame}
\frametitle{Telomere length}

{\tiny \url{http://www.pnas.org/content/101/49/17312}}

\begin{quote}
People who are stressed over long periods tend to look haggard, and it is commonly thought that psychological stress leads to premature aging and the earlier onset of diseases of aging. 

...

This design allowed us to examine the importance of perceived stress and measures of objective stress (caregiving status and chronicity of caregiving stress based on the number of years since a child's diagnosis).

...

Telomere length values were measured from DNA by a quantitative PCR assay that determines the relative ratio of telomere repeat copy number to single-copy gene copy number (T/S ratio) in experimental samples as compared with a reference DNA sample.
\end{quote}

\end{frame}


\subsection{Interpretation}
\frame{\frametitle{Interpretation}

	\vspace{-0.2in}

	\[ E[Y_i|X_i=x] = \beta_0 + \beta_1 x \qquad V[Y_i|X_i=x] = \sigma^2 \]

\pause
	
	\begin{itemize}
	\item	If $X_i=0$, then $E[Y_i|X_i=0] = \beta_0$. \pause 
	
	\alert{$\beta_0$ is the expected response when the explanatory variable is zero.} \pause 
	
	\vspace{0.2in} 
	
	\item If $X_i$ increases from $x$ to $x+1$, then 
	\[ \begin{array}{rl}
	E[Y_i|X_i=x+1] &= \beta_0+\beta_1x+\beta_1 \pause \\
	\uncover<6->{-} E[Y_i|X_i=x\phantom{\,+\,1}] &= \beta_0+\beta_1 x  \pause \\
	\hline
	&= \beta_1 \pause
	\end{array} \]
	
	\alert{$\beta_1$ is the expected increase in the response for each unit increase in the explanatory variable.} 
	
	\vspace{0.2in} \pause
	
	\item 
	
	\alert{$\sigma$ is the standard deviation of the response for a fixed value of the explanatory variable.}
	\end{itemize}
}

\subsection{Parameter Estimation}
\frame{\frametitle{}
	\small

	Remove the mean:
	\[ Y_i = \beta_0+\beta_1 X_i +e_i \qquad e_i \stackrel{iid}{\sim} N(0,\sigma^2) \]
	
	 \pause
	
	So the error is
	\[ e_i = Y_i - (\beta_0+\beta_1X_i) \]
	\pause which we approximate by the \alert{residual}
	\[ r_i = \hat{e}_i = Y_i - (\hat{\beta}_0+\hat{\beta}_1X_i) \]
	\pause The least squares, maximum likelihood, and Bayesian estimators are \pause
	\[ \begin{array}{rl}
  \hat{\beta}_1 &= SXY/SXX \\
	\hat{\beta}_0 &= \overline{Y}-\hat{\beta}_1\overline{X} \\ 
	\hat{\sigma}^2 &=  SSE/(n-2) \qquad \mbox{df}=n-2 \\ \pause
  \\
  \overline{X} &= \frac{1}{n} \sum_{i=1}^n X_i \\
	\overline{Y} &= \frac{1}{n} \sum_{i=1}^n Y_i \\ \pause 
  \\
  SXY &= \sum_{i=1}^n (X_i-\overline{X})(Y_i-\overline{Y}) \\
	SXX &= \sum_{i=1}^n (X_i-\overline{X})(X_i-\overline{X}) = \sum_{i=1}^n (X_i-\overline{X})^2 \\
	SSE &= \sum_{i=1}^n r_i^2 
	\end{array} \]
}

\subsection{Standard errors}
\frame{\frametitle{}
\small
	How certain are we about $\hat{\beta}_0$ and $\hat{\beta}_1$ being equal to $\beta_0$ and $\beta_1$? 
	
	\vspace{0.2in} \pause
	
	We quantify this uncertainty using their standard errors:
	\[ \begin{array}{rlll}
	SE(\beta_0) &= \hat{\sigma} \sqrt{\frac{1}{n} + \frac{\overline{X}^2}{(n-1)s_X^2}} & df=n-2 \\ \pause
	SE(\beta_1) &= \hat{\sigma} \sqrt{\phantom{\frac{1}{n} +\,\, }\frac{1}{(n-1)s_X^2}} & df=n-2 \\ \pause
	\\
	s_X^2 &= SXX/(n-1) \\ 
	s_Y^2 &= SYY/(n-1) \\ \pause
	SYY &=  \sum_{i=1}^n (Y_i-\overline{Y})^2 \\ \pause
	\\
	r_{XY} &= \frac{SXY/(n-1)}{s_Xs_Y} &&\pause \mbox{correlation coefficient} \\ \pause
	R^2 &= r^2_{XY} \pause &= \frac{SST-SSE}{SST} \pause & \mbox{coefficient of determination} \\ \pause
	SST &= SYY = \sum_{i=1}^n (Y_i-\overline{Y})^2 \pause 
	\end{array} \]
The coefficient of determination ($R^2$) is the proportion of the total response variation explained by the explanatory variable(s).
}


\begin{frame}[fragile]
\frametitle{}
<<echo=FALSE>>=
Telomeres$jyears = jitter(Telomeres$years)
plot(telomere.length~jyears, Telomeres,
     main="Telomere length vs years post diagnosis",
     xlab="Years post diagnosis (jittered)",
     ylab="Telomere length")

m = lm(telomere.length~years, Telomeres)
abline(m, col="red", lwd=2)

segments(Telomeres$jyears, predict(m), 
         Telomeres$jyears, predict(m)+residuals(m), 
         lty=2, col="red")
@
\end{frame}


\subsection{Pvalues and confidence intervals}
\frame{\frametitle{Pvalues and confidence interval}
	We can compute two-sided pvalues via
	\[ 2P\left(t_{n-2}<-\left|\frac{\hat{\beta_0}}{SE(\beta_0)}\right|\right) \qquad \mbox{and} \qquad 2P\left(t_{n-2}<-\left|\frac{\hat{\beta_1}}{SE(\beta_1)}\right|\right) \]
	\pause These test the null hypothesis that the corresponding parameter is zero.
	
	\vspace{0.4in} \pause 
	
	We can construct $100(1-\alpha)\%$ two-sided confidence intervals via
	\[ \hat{\beta}_0 \pm t_{n-2}(1-\alpha/2) SE(\beta_0) \qquad \mbox{and} \qquad \hat{\beta}_1 \pm t_{n-2}(1-\alpha/2) SE(\beta_1)  \]

	These provide ranges of the parameters consistent with the data.
}



\begin{frame}[fragile]
\frametitle{Calculations by hand}
{\tiny
<<echo=FALSE>>=
ddply(Telomeres, .(), summarize,
      n = length(years),
      Xbar = mean(years),
      Ybar = mean(telomere.length),
      s_X = sd(years),
      s_Y = sd(telomere.length),
      r_XY = cor(telomere.length,years)
      )[,-1]
@

\[ \begin{array}{rl}
SXX &= (n-1) s_x^2 = (39-1)\times 2.935427^2 = 327.4358 \\
SYY &= (n-1) s_Y^2 = (39-1)\times 0.1797731^2 = 1.228098 \\
SXY &= (n-1) s_X s_Y r_{XY} = (39-1) \times 2.935427 \times 0.1797731 \times-0.4306534 = -8.635897 \\
\hat{\beta}_1 &= SXY/SXX = -8.635897/327.4358 = -0.02637432 \\
\hat{\beta}_0 &= \overline{Y}-\hat{\beta}_1\overline{X} = 1.220256 - (-0.02637432)\times 5.589744 = 1.367682 \\
R^2 &= r_{XY}^2 = (-0.4306534)^2 = 0.1854624 \\
SSE &= SYY(1-R^2) = 1.228098(1-0.1854624) = 1.000332 \\
\hat{\sigma}^2 &= SSE/(n-2) = 1.000332/(39-2) = 0.027036 \\
\hat{\sigma} &= \sqrt{\hat{\sigma}^2} = \sqrt{0.027036} = 0.1644263 \\
SE(\hat{\beta}_0) &= \hat{\sigma}\sqrt{\frac{1}{n} + \frac{\overline{X}^2}{(n-1)s_x^2}} =  0.1644263 \sqrt{\frac{1}{39} + \frac{ 5.589744^2}{327.4358}} = 0.05721115 \\
SE(\hat{\beta}_1) &= \hat{\sigma}\sqrt{\frac{1}{(n-1)s_x^2}} =  0.1644263 \sqrt{\frac{1}{327.4358}} = 0.009086742 \\
p_{H_0:\beta_0=0} &= 2P\left(t_{n-2} < -\left| \frac{1.367682}{0.05721115} \right|\right) = 2P(t_{37} < - 23.90586) < 0.0001 \\
p_{H_0:\beta_1=0} &= 2P\left(t_{n-2} < -\left| \frac{-0.02637432 }{0.009086742} \right|\right) = 2P(t_{37} < - 2.902506) < 0.0062 \\
CI_{95\%\, \beta_0} &= \hat{\beta}_0 \pm t_{n-2}(1-\alpha/2) SE(\hat{\beta}_0) = 1.367682 \pm 2.026192\times  0.05721115 = (1.251761, 1.483603) \\
CI_{95\%\, \beta_1} &= \hat{\beta}_1 \pm t_{n-2}(1-\alpha/2) SE(\hat{\beta}_1) = -0.02637432  \pm 2.026192\times  0.009086742 = (-0.044785804 -0.007962836)
\end{array} \]
}
\end{frame}

\frame[containsverbatim]{\frametitle{}
\tiny
\begin{verbatim}
DATA t;
  INFILE 'telomeres.csv' DSD FIRSTOBS=2;
  INPUT years length;

PROC CORR DATA=t;
  VAR length;
  WITH years;
  RUN;

                                       The CORR Procedure

                                   1 With Variables:    years    
                                   1      Variables:    length   


                                       Simple Statistics
 
   Variable           N          Mean       Std Dev           Sum       Minimum       Maximum

   years             39       5.58974       2.93543     218.00000       1.00000      12.00000
   length            39       1.22026       0.17977      47.59000       0.84000       1.63000


                            Pearson Correlation Coefficients, N = 39 
                                   Prob > |r| under H0: Rho=0
 
                                                    length

                                       years      -0.43065
                                                    0.0062
\end{verbatim}
}




\frame[containsverbatim]{\frametitle{}
\tiny
\begin{verbatim}
PROC GLM DATA=t;
  MODEL length = years / SOLUTION CLPARM;
  RUN;

                                        The GLM Procedure
                             Number of Observations Read          39
                             Number of Observations Used          39
 
Dependent Variable: length   

                                               Sum of
       Source                      DF         Squares     Mean Square    F Value    Pr > F
       Model                        1      0.22776588      0.22776588       8.42    0.0062
       Error                       37      1.00033156      0.02703599                     
       Corrected Total             38      1.22809744                                     

                       R-Square     Coeff Var      Root MSE    length Mean
                       0.185462      13.47473      0.164426       1.220256

       Source                      DF       Type I SS     Mean Square    F Value    Pr > F
       years                        1      0.22776588      0.22776588       8.42    0.0062

       Source                      DF     Type III SS     Mean Square    F Value    Pr > F
       years                        1      0.22776588      0.22776588       8.42    0.0062

                                   Standard
 Parameter         Estimate           Error    t Value    Pr > |t|      95% Confidence Limits
 Intercept      1.367682067      0.05721112      23.91      <.0001     1.251761335  1.483602799
 years         -0.026374315      0.00908674      -2.90      0.0062    -0.044785794 -0.007962836

\end{verbatim}
}




\begin{frame}[fragile]
\frametitle{Regression in R}

<<>>=
m = lm(telomere.length~years, Telomeres)
with(Telomeres, cor(telomere.length,years))
anova(m)
@

\end{frame}


\begin{frame}[fragile]
\frametitle{Regression in R}

<<>>=
m = lm(telomere.length~years, Telomeres)
summary(m)
confint(m)
@

\end{frame}


\begin{frame}
\frametitle{Conclusion}

Telomere length at the time of diagnosis of a child's chronic illness is estimated to be 1.37 with a 95\% confidence interval of (1.25, 1.48). \pause For each year increase since diagnosis, the length decreases by 0.026 with a 95\% confidence interval of (0.008, 0.045). \pause The proportional of variability in telomere length described by years since diagnosis is 18.5\%. 

\vspace{0.2in} \pause


{\tiny \url{http://www.pnas.org/content/101/49/17312}}
\begin{quote}
The zero-order correlation between chronicity of caregiving [years] and mean telomere length, r,is $-0.445$ (P $<$0.01). [$R^2=0.198$ was shown in the plot.]
\end{quote}

{\tiny 
\begin{remark}
I'm guessing our analysis and that reported in the paper don't match exactly due to a discrepancy in the data.
\end{remark}
}

\end{frame}



\subsection{Summary}
\frame{\frametitle{Summary}
\begin{itemize}[<+->]
\item The \alert{simple linear regression} model is 
	\[ Y_i \stackrel{ind}{\sim} N(\beta_0+\beta_1 X_i, \sigma^2) \]
	where $Y_i$ and $X_i$ are the response and explanatory variable, respectively, for individual $i$.

	\vspace{0.1in} 
	
\item Know how to use SAS/R to obtain $\hat{\beta}_0$, $\hat{\beta}_1$, $\hat{\sigma}^2$, $R^2$, pvalues, CIs, etc. 
	
	\vspace{0.1in}
	
\item Interpret SAS output
	\begin{itemize}
	\item At a value of zero for the explanatory variable ($X_i=0$), $\beta_0$ is the expected value for the response ($Y_i$).
	\item For each unit increase in the explanatory variable value, $\beta_1$ is the expected increase in the response.
	\item At a constant value of the explanatory variable, $\sigma^2$ is the variance of the responses. 
	\item The coefficient of determination ($R^2$) is the percentage of the total response variation explained by the explanatory variable(s).
	\end{itemize}
\end{itemize}
}



\section{Statements about a particular value of $X$}

\begin{frame}
\frametitle{What is $E[Y|X=x]$?}

We know $\beta_0 = E[Y|X=0]$, but what about $X=x$? \pause

\[ E[Y|X=x] = \beta_0+\beta_1 x \]
\pause 
which we can estimate via 
\[ \widehat{E[Y|X=x]} = \hat{\beta}_0 + \hat{\beta}_1x \]
\pause
but there is uncertainty in both $\beta_0$ and $\beta_1$. \pause So the standard error of $E[Y|X=x]$ is 
\[ SE(E[Y|X=x]) = \hat{\sigma} \sqrt{\frac{1}{n} + \frac{(\overline{X}-x)^2}{(n-1)s_X^2}}  \]
and a $100(1-\alpha)$\% confidence interval is 
\[ \hat{\beta}_0 + \hat{\beta}_1x \pm t_{n-2}(1-\alpha/2)SE(E[Y|X=x]) \]

\end{frame}



\begin{frame}
\frametitle{What do we predict about $Y$ at $X=x$?}

On the last slide, we calculated $E[Y|X=x]$ and it's uncertainty\pause, but if we are trying to predict a new observation, we need to account for the sampling variablity $\sigma^2$. \pause Thus a prediction about $Y$ at a new $X=x$ is still

\[ Pred{Y|X=x} = \hat{\beta}_0 + \hat{\beta}_1 x \]
but the uncertainty includes the variability due to $\sigma^2$. \pause  So the standard error of $Pred{Y|X=x}$ is 
\[ SE(Pred{Y|X=x}) = \hat{\sigma} \sqrt{1+\frac{1}{n} + \frac{(\overline{X}-x)^2}{(n-1)s_X^2}}  \]
and a $100(1-\alpha)$\% confidence interval is 
\[ \hat{\beta}_0 + \hat{\beta}_1x \pm t_{n-2}(1-\alpha/2)SE(Pred{Y|X=x}). \]
\end{frame}



\frame[containsverbatim]{\frametitle{}
\tiny
\begin{verbatim}
DATA tnew;
  INPUT years;
  DATALINES;
  4
  ;

DATA combined;
  SET t tnew;
  RUN;

PROC PRINT DATA=combined;
  WHERE years=4;
  RUN;
  
                                     Obs    years    length

                                      10      4       1.51 
                                      11      4       1.31 
                                      15      4       1.03 
                                      16      4       0.84 
                                      40      4        .   
                                      
PROC GLM DATA=combined;
 MODEL length = years;
 OUTPUT OUT=combinedreg PREDICTED=predicted  LCLM=lclm UCLM=uclm LCL=lcl UCL=ucl;
 RUN;

PROC PRINT DATA=combinedreg;
  WHERE length=.;             /* . is missing data in SAS */
  RUN;
  
         Obs    years    length    predicted      lclm       uclm       lcl        ucl
          40      4         .       1.26218     1.20133    1.32303    0.92351    1.60086
\end{verbatim}
}


\begin{frame}[fragile]

<<>>=
m = lm(telomere.length~years, Telomeres)
new = data.frame(years=4)
predict(m, new, interval="confidence")  
predict(m, new, interval="prediction") 
@
\end{frame}




\begin{frame}[fragile]

<<echo=FALSE, fig.height=6, fig.width=7, out.width='0.8\\textwidth'>>=
plot(telomere.length~years, Telomeres, pch=19)
abline(m)
d = data.frame(years=seq(0,13,by=.1))
tmp = predict(m, d, interval="confidence")  
lines(d$years, tmp[,2], lwd=2, lty=2, col=2)
lines(d$years, tmp[,3], lwd=2, lty=2, col=2)
tmp = predict(m, d, interval="prediction")  
lines(d$years, tmp[,2], lwd=2, lty=3, col=3)
lines(d$years, tmp[,3], lwd=2, lty=3, col=3)
legend("topright", c("Regression line","Confidence bands","Prediction bands"), lty=1:3, lwd=2, col=1:3,
       bg="white")
@
\end{frame}




\section{Lack-of-fit F-test}
\frame{\frametitle{Testing Composite hypotheses}
  Comparing two models
	\begin{itemize}
	\item $H_0:$ \alert{(reduced)}
	\item $H_1:$ \alert{(full)}
	\end{itemize}
	
	\vspace{0.2in} \pause
	
	\small
	Do the following
	\begin{enumerate}[1.]
	\item Calculate extra sum of squares.
	\item Calculate extra degrees of freedom
	\item Calculate 
	\[ \mbox{F-statistic} = \frac{\mbox{Extra sum of squares / Extra degrees of freedom}}{\hat{\sigma}^2_{full}} \]
	\item Compare this to an F-distribution with 
		\begin{itemize}
		\item numerator degrees of freedom = extra degrees of freedom
		\item denominator degrees of freedom = degrees of freedom in estimating $\hat{\sigma}_{full}^2$
		\end{itemize}
	\end{enumerate}
}


\frame{\frametitle{Lack-of-fit F-test}
	Two models:
	
	\begin{tabular}{lll}
	ANOVA: & $Y_{ij} \stackrel{ind}{\sim} N(\mu_i,\sigma^2)$ & \pause \uncover<3->{\alert{(full)}} \\
	Regression: & $Y_{ij} \stackrel{ind}{\sim} N(\beta_0+\beta_1 X_i, \sigma^2)$ & \uncover<3->{\alert{(reduced)}}
	\end{tabular}
	
	\vspace{0.2in} \pause \pause
	
	\begin{itemize}[<+->]
	\item Regression model is reduced:
	\begin{itemize}
	\item ANOVA has $J$ parameters for the mean
	\item Regression has 2 parameters for the mean
	\item Set $\mu_{i} = \beta_0+\beta_1 X_i$.
	\end{itemize}
	\item Small pvalues indicate a lack-of-fit, i.e. the reduced model is not adequate.
	\item Lack-of-fit F-test requires multiple observations at a few $X_i$ values!
	\end{itemize}
}

\begin{frame}[fragile]
\frametitle{Telomere length}
<<echo=FALSE>>=
ggplot(Telomeres, aes(factor(years), telomere.length))+
  geom_boxplot()+
  geom_jitter()+
  labs(x="Years", y="Telomere length", 
       title="Telomere length vs years since diagnosis")
@
\end{frame}

\begin{frame}[fragile]
\frametitle{Telomere length}
<<echo=FALSE>>=
ggplot(Telomeres, aes(years, telomere.length))+
  geom_jitter()+
  geom_smooth(method=lm, se=FALSE)+
  labs(x="Years", y="Telomere length", 
       title="Telomere length vs years since diagnosis")
@
\end{frame}

\subsection{SAS code}
\frame[containsverbatim]{\frametitle{SAS code}
\tiny
\begin{verbatim}
DATA t;
  INFILE 'telomeres.csv' DSD FIRSTOBS=2;
  INPUT years length;

PROC REG DATA=t;
  MODEL length = years / CLB LACKFIT;
  RUN;

                                        The REG Procedure
                                          Model: MODEL1
                                   Dependent Variable: length 

                             Number of Observations Read          39
                             Number of Observations Used          39


                                      Analysis of Variance
 
                                             Sum of           Mean
         Source                   DF        Squares         Square    F Value    Pr > F

         Model                     1        0.22777        0.22777       8.42    0.0062
         Error                    37        1.00033        0.02704                     
           Lack of Fit             9        0.18223        0.02025       0.69    0.7093
           Pure Error             28        0.81810        0.02922                     
         Corrected Total          38        1.22810           
\end{verbatim}
Indicates no evidence for a lack of fit, i.e. regression seems adequate.
}



\begin{frame}[fragile]
<<>>=
m_anova = lm(telomere.length ~ as.factor(years), Telomeres)
m_reg   = lm(telomere.length ~           years , Telomeres)
anova(m_reg, m_anova)
@
No evidence of a lack of fit. 

\end{frame}


\subsection{Summary}
\frame{\frametitle{Summary}
	\begin{itemize}[<+->]
	\item Lack-of-fit F-test tests the assumption of linearity
	\item Needs multiple observations at various explanatory variable values
	\item Small pvalue indicates a lack-of-fit, i.e. means are not linear
		\begin{itemize}
		\item Transform response, e.g. log
		\item Transform explanatory variable
		\item Add other explanatory variables
		\end{itemize}
	\end{itemize}
}



% Put in interpretable intercept

\begin{comment}
\section{Regression Diagnostics}
\frame{\frametitle{Regression}
  The simpler linear regression model is 
	\[ Y_i \stackrel{ind}{\sim} N(\beta_0+\beta_1 X_i, \sigma^2) \]
	\pause this can be rewritten as 
	\[ Y_i = \beta_0 + \beta_1 X_i + e_i \qquad e_i \stackrel{ind}{\sim} N(0,\sigma^2) \]
	\pause where we estimate the errors via the residuals
	\[ r_i = \hat{e}_i = Y_i - (\hat{\beta}_0+\hat{\beta}_1 X_i). \]
	
	\vspace{0.2in} \pause
	
	Key assumptions are:
	\begin{itemize}[<+->]
	\item Linearity between mean response and explanatory variable
	\item Normality of the errors
	\item Constant variance of the errors
	\item Independence between observations
	\end{itemize}
}

\subsection{Linearity}
\begin{frame}[fragile]
\frametitle{Linearity}
	Assess using scatterplots of transformed response vs transformed explanatory variable:
	
<<echo=FALSE>>=
n = 100
x = runif(n,0,10)
y = rnorm(n,x)
set.seed(1)

myplot = function(x,y,main="") {
  plot(x,y,axes=FALSE, frame=TRUE, main=main)
}

par(mfrow=c(2,4), mar=c(0,0,4,0)+.5)
myplot(x, y)
myplot(x, exp(y))
myplot(exp(x), y)
myplot(exp(x), exp(y))
myplot(x, y)
myplot(x, y, "log(y)")
myplot(x, y, "log(x)")
myplot(x, y, "log(x), log(y)")
@
\end{frame}

\subsection{Normality}
\begin{frame}[fragile]
\frametitle{Normality}
	These are normal.
<<echo=FALSE>>=
n = 1000
x = rnorm(n)
par(mfrow=c(1,3))
for (i in c(10,100,1000)) { qqnorm(x[1:i], main=paste("n=",i)); qqline(x[1:i]) }
@
	SAS swaps the x and y axes
\end{frame}

\begin{frame}[fragile]
\frametitle{Normality}
	These are normal.
<<echo=FALSE>>=
par(mfrow=c(2,5), mar=rep(0,4)+.5)
for (i in 1:10) {
  x = rnorm(100)
  qqnorm(x, main="", xlab="", ylab=""); qqline(x)
}
@
	SAS swaps the x and y axes
\end{frame}
\begin{frame}
\frametitle{Normality}
<<echo=FALSE>>=
n=1000
x = rnorm(n, 10)
par(mfrow=c(2,2), mar=c(0,0,4,0)+.5)
qqnorm(x, main="normal"); qqline(x)
qqnorm(exp(x), main="right-skewed", xlab="", ylab=""); qqline(exp(x))
qqnorm(log(x), main="left-skewed", xlab="", ylab=""); qqline(log(x))
qqnorm(y <- rt(n,5), main="heavy-tailed", xlab="", ylab=""); qqline(y)
@
	SAS swaps the x and y axes
\end{frame}

\subsection{Constant variance}
\begin{frame}[fragile]
\frametitle{Constant variance}
	Most common non-constant variance is when the variance increases with the mean
<<echo=FALSE>>=
d = read.csv("reddye40.csv")
m = lm(weeks~dose,d)
plot(predict(m), residuals(m), main="Red Dye 40 residuals vs fitted values")
@
\end{frame}

\subsection{Independence}
\frame{\frametitle{Independence}
	Lack of independence includes
	\begin{itemize}
	\item Cluster effect
	\item Serial correlation
	\item Spatial association
	\end{itemize}
	
	\vspace{0.2in} \pause
	
	Make plots of residuals vs relevant explanatory variables and look for patterns, \pause e.g.
	\begin{itemize}[<+->]
	\item Residuals vs groups (prefer blocking)
	\item Residuals vs time (or observation number)
	\item Residuals vs spatial variable 
	\end{itemize}
}



\subsection{Summary}
\frame{\frametitle{Summary}
	Often the best strategy is graphical exploration of the data, \pause here are some relevant graphs: \pause
	\begin{itemize}
	\item transformed response vs transformed explanatory
	\item transformed response vs transformed explanatory
	\item qqplot of residuals
	\item residual vs fitted value
	\item residual vs explanatory
	\item residual vs observation number
	\item residual vs any other variable
	\end{itemize}
}

\end{comment}



\end{document}
