\documentclass[handout]{beamer}

\usepackage{verbatim}

\graphicspath{{figures/}}

\usetheme{AnnArbor}
\usecolortheme{beaver}

\setlength{\unitlength}{\textwidth}  % measure in textwidths
\usepackage[normalem]{ulem}

\setbeamertemplate{navigation symbols}{}
\setbeamertemplate{enumerate items}[default]
\setbeamertemplate{enumerate subitem}{\alph{enumii}.}
\setbeamertemplate{enumerate subsubitem}{\roman{enumiii}.}
\setkeys{Gin}{width=0.6\textwidth}

\title{Bayesian Spatial Analysis}
\author[Jarad Niemi]{Dr. Jarad Niemi}
\institute[Iowa State]{Iowa State University}
\date{\today}

\newcommand{\mG}{\mathrm{\Gamma}}
\newcommand{\I}{\mathrm{I}}
\newcommand{\mySigma}{\mathrm{\Sigma}}
\newcommand{\ind}{\stackrel{ind}{\sim}}

\begin{document}

%\section{Temp??} \begin{comment}


<<options, results='hide', echo=FALSE>>=
# These are only needed for the slides
# No need to run if you are just running the R code
opts_chunk$set(fig.width=7, 
               fig.height=5, 
               out.width='.8\\linewidth', 
               fig.align='center', 
               size='tiny',
               echo=FALSE, 
               cache=TRUE)
options(width=100)
@

<<libraries, echo=FALSE, message=FALSE, warning=FALSE>>=
library(ggplot2)
library(plyr)
library(dplyr)
library(reshape2)
library(maps)
library(spBayes)
library(fields)
@

<<set_seed, echo=FALSE>>=
set.seed(2)
@

\frame{\maketitle}



\section{Spatial modeling}
\begin{frame}
\frametitle{Spatial modeling}

Three main types of spatial data:
\begin{itemize}
\item Point-referenced (georeferenced)
\item Areal-referenced
\item Point process
\end{itemize}
\end{frame}


\begin{frame}
\frametitle{Point-referenced spatial data}
Features
\begin{itemize}[<+->]
\item Some spatial domain $\mathcal{D}$ is under study
\item Measured spatial locations $s\in \mathcal{D}$ are pre-determined
\item Some quantity, $Y(s)$, is measured at each location $s\in \mathcal{D}$
\end{itemize}

\vspace{0.2in} \pause

Examples
\begin{itemize}[<+->]
\item Air quality monitoring
\item Bird point counts
\item Coastal tide level monitoring
\item Earthquake monitoring
\end{itemize}
\end{frame}



\begin{frame}
\frametitle{Areal-referenced spatial data}
Features
\begin{itemize}[<+->]
\item Some set of spatial regions $1,\ldots,S$ are pre-determined
\item Some quantity, $Y_s$, is measured as an aggregate over that region
\end{itemize}

\vspace{0.2in} \pause

Examples
\begin{itemize}[<+->]
\item Disease occurrence per county
\item Unemployment rate per state
\item Inflation per country
\end{itemize}
\end{frame}



\begin{frame}
\frametitle{Point-process spatial data}
Features
\begin{itemize}[<+->]
\item Some spatial domain $\mathcal{D}$ is under study
\item Spatial locations $s\in \mathcal{S}\subset \mathcal{D}$ are random
\item $Y(s)=1$ indicates an occurence of the event
\end{itemize}

\vspace{0.2in} \pause

Examples
\begin{itemize}[<+->]
\item Locations of Mayan ruins
\item Locations of invasive species
\item Locations of caught Lingcod
\end{itemize}
\end{frame}




\section{Point-referenced spatial data}
\begin{frame}
\frametitle{Point-referenced spatial data}

Let $Y(s)$ for $s\in\mathcal{D}\subseteq \mathbb{R}^d$ be a spatial process. \pause Let $E[Y(s)]=0$ for all $s\in\mathcal{D}$ because we will model the mean separately.

\vspace{0.2in} \pause

Assumptions:
\begin{itemize}[<+->]
\item Intrinsic stationarity
\item Isotropy
\item Weak stationarity
\item Strong stationarity
\item Gaussian process
\end{itemize}

\end{frame}




\begin{frame}
\frametitle{Example spatial process}
\vspace{-0.2in}
<<spatial_process,out.width='\\linewidth'>>=
library(fields)
fit<- Tps( BD[,1:4], BD$lnya)  # fit surface to data 

glist<- list( KCL=29.77, MgCl2= seq(3,7,length.out=1e2), KPO4=32.13, 
                     dNTP=seq( 250,1500,length.out=1e2))

out.p<- predictSurface(fit, glist)
surface(out.p, type="C", main='log of DNA amplification rate (KCL=29.77, KPO4=32.13)')
@
\end{frame}




\subsection{Assumptions}
\begin{frame}
\frametitle{Intrinsic stationarity}
\begin{definition}
A process $Y(s)$ is \alert{intrinsically stationary} if ($E[Y(s+h)-Y(s)]=0$ and)
\[ E[(Y(s+h)-Y(s))^2] = Var[Y(s+h)-Y(s)] = 2\gamma(h) \]
when $s,s+h\in\mathcal{D}$. \pause We call $2\gamma(h)$ the \alert{variogram} and $\gamma(h)$ the \alert{semivariogram}.
\end{definition}
  
% \vspace{0.2in} \pause
% 
% Note that here we are only defining the first and second moments of the differences, but it says nothing about the joint distribution and thus provides no likelihood.

\vspace{0.2in} \pause

\begin{definition}
A process $Y(s)$ is \alert{isotropic} if the semivariogram function depends only on $||h||$, the length of the separation vector. Otherwise the process is \alert{anisotropic}.
  \end{definition}

\end{frame}



\begin{frame}
\frametitle{Weak stationarity}
\begin{definition}
A process $Y(s)$ has \alert{weak stationarity} if ($E[Y(s)]=\mu$ and)
$Cov[Y(s),Y(s+h)] = C(h)$
when $s,s+h\in\mathcal{D}$. \pause We call $C(h)$ the covariance function or covariogram.
\end{definition}

\vspace{0.2in} \pause

Since $\gamma(h) = C(0)-C(h)$, a weakly stationary process is also intrinsicly stationary. 

\vspace{0.2in} \pause

If the spatial process is \alert{ergodic}, then $C(h)\to 0$ as $||h||\to\infty$ \pause and $\lim_{||h||\to\infty} \gamma(h) = C(0)$. \pause Thus 
\[ 
C(h) = C(0) - \gamma(h) = \lim_{||u||\to\infty} \gamma(u)-\gamma(h).
\]
\pause
Thus, if the process is ergodic, an intrinsicly stationary process is also weakly stationary. 

\end{frame}



\begin{frame}
\frametitle{Covariance functions for isotropic models}
\tiny
\begin{tabular}{lll}
Model & Covariance function, $C(t)$ & Semivariogram, $\gamma(t)$ \\
\hline
Linear & 
$C(t)$ does not exist & 
$\gamma(t) = \left\{ \begin{array}{ll} \tau^2 + \sigma^2 t & \mbox{if }t>0 \\ 0 & \mbox{otherwise} \end{array} \right.$ \\

Spherical & 
$C(t) = \left\{ \begin{array}{l}
0 \\
\sigma^2\left[1-\frac{3}{2}\phi t + \frac{1}{2}(\phi t)^3 \right]  \\
 \tau^2+\sigma^2 \end{array} \right.$ &
$\gamma(t) = \left\{ \begin{array}{ll} 
\tau^2 + \sigma^2 & \mbox{if }t\ge 1/\phi \\
\tau^2 + \sigma^2 \left[ \frac{3}{2}\phi t - \frac{1}{2}(\phi t)^3 \right] & 0<t\le 1/\phi \\
 0 & \mbox{otherwise} \end{array} \right.$ \\
 
Exponential & 
$C(t) = \left\{ \begin{array}{l}
\sigma^2 \exp(-\phi t)  \\
 \tau^2+\sigma^2 \end{array} \right.$ &
$\gamma(t) = \left\{ \begin{array}{ll} 
\tau^2 + \sigma^2 \left[ 1-\exp(-\phi t) \right] & t>0 \\
 0 & \mbox{otherwise} \end{array} \right.$ \\
 
Powered exponential & 
$C(t) = \left\{ \begin{array}{l}
\sigma^2 \exp(-|\phi t|^p)  \\
 \tau^2+\sigma^2 \end{array} \right.$ &
$\gamma(t) = \left\{ \begin{array}{ll} 
\tau^2 + \sigma^2 \left[ 1-\exp(-|\phi t|^p) \right] & t>0 \\
 0 & \mbox{otherwise} \end{array} \right.$ \\
 
Gaussian & 
$C(t) = \left\{ \begin{array}{l}
\sigma^2 \exp(-\phi^2 t^2)  \\
 \tau^2+\sigma^2 \end{array} \right.$ &
$\gamma(t) = \left\{ \begin{array}{ll} 
\tau^2 + \sigma^2 \left[ 1-\exp(-\phi^2 t^2) \right] & t>0 \\
 0 & \mbox{otherwise} \end{array} \right.$ \\
 
Rational quadratic & 
$C(t) = \left\{ \begin{array}{l}
\sigma^2 \left( 1- \frac{t^2}{(1+\phi^2)} \right)  \\
 \tau^2+\sigma^2 \end{array} \right.$ &
$\gamma(t) = \left\{ \begin{array}{ll} 
\tau^2 + \sigma^2 \frac{t^2}{(1+\phi^2)} & t>0 \\
 0 & \mbox{otherwise} \end{array} \right.$ \\
 
Wave & 
$C(t) = \left\{ \begin{array}{l}
\sigma^2 \frac{\sin(\phi t)}{\phi t}  \\
 \tau^2+\sigma^2 \end{array} \right.$ &
$\gamma(t) = \left\{ \begin{array}{ll} 
\tau^2 + \sigma^2 \left[ 1-\frac{\sin(\phi t)}{\phi t} \right] & t>0 \\
 0 & \mbox{otherwise} \end{array} \right.$ \\
 
Power law & 
$C(t)$ does not exist  &
$\gamma(t) = \left\{ \begin{array}{ll} 
\tau^2 + \sigma^2 t^\lambda & t>0 \\
 0 & \mbox{otherwise} \end{array} \right.$ \\
  
Mat\'{e}rn & 
$C(t) = \left\{ \begin{array}{l}
\frac{\sigma^2}{2^{\nu-1}\mG(\nu)}(2\sqrt{v}t\phi)^\nu K_\nu(2\sqrt{\nu}t\phi)  \\
 \tau^2+\sigma^2 \end{array} \right.$ &
$\gamma(t) = \left\{ \begin{array}{ll} 
\tau^2 + \sigma^2 \left[ 1-\frac{\left(2\sqrt{\nu}t\phi\right)^\nu}{2^{\nu-1}\mG(\nu)}(2\sqrt{v}t\phi)^\nu K_\nu(2\sqrt{\nu}t\phi) \right] & t>0 \\
 0 & \mbox{otherwise} \end{array} \right.$ \\
  
Mat\'{e}rn ($\nu=3/2$) & 
$C(t) = \left\{ \begin{array}{l}
\sigma^2(1+\phi t) \exp(-\phi t)  \\
 \tau^2+\sigma^2 \end{array} \right.$ &
$\gamma(t) = \left\{ \begin{array}{ll} 
\tau^2 + \sigma^2 \left[ 1-(1+\phi t) \exp(-\phi t) \right] & t>0 \\
 0 & \mbox{otherwise} \end{array} \right.$ \\
\hline
\end{tabular}

\end{frame}



\begin{frame}
\frametitle{Spherical semivariogram}
<<>>=
ff <- function(t,tau2=.2,sigma2=1,phi=1) {
  (t==0)*0+
	(t>0 & t<1/phi)*(tau2+sigma2*(3*phi*t/2-(phi*t)^3/2))+
	(t>=1/phi)*(tau2+sigma2)
}

curve(ff,0.0001,2, ylim=c(0,1.2), xlab="t", ylab=expression(gamma(t)), main="Spherical semivariogram", lwd=2)
points(0,0, pch=16)
segments(1.0,0,1.0,0.2, col="red", lwd=2);     text(1.0,0.1,expression(paste("nugget (",tau^2,")")), col="red", pos=4, cex=1)
segments(1.25,0.2,1.25,1.2, col="red", lwd=2); text(1.25,0.8,expression(paste("partial sill (",sigma^2,")")), col="red", pos=2, cex=1)
segments(1.5,0,1.5,1.2, col="red", lwd=2);     text(1.5,0.6,expression(paste("sill (",tau^2+sigma^2,")")), col="red", pos=4, cex=1)
segments(0,.6,1,.6, col="red", lwd=2);         text(.5,.6,expression(paste("range (",1/phi,")")), col="red", pos=1, cex=1)
@
\end{frame}



\begin{frame}
\frametitle{Mat\'{e}rn}
Perhaps the most important isotropic process is the Mat\'{e}rn process with covariance
\[ C(t) = \left\{ \begin{array}{ll} 
\frac{\sigma^2}{2^{\nu-1}\mathrm\Gamma(\nu)} (2\sqrt{\nu}t\phi)^\nu K_\nu(2\sqrt{\nu}t\phi) & t>0 \\
\tau^2 + \sigma^2 & t=0
\end{array}\right. \]
and variogram
\[ \gamma(t) = \left\{ \begin{array}{cl} 
\tau^2 + \sigma^2\left[ 1-\frac{(2\sqrt{\nu}t\phi)^\nu}{2^{\nu-1}\mathrm\Gamma(\nu)} K_\nu(2\sqrt{\nu}t\phi)\right] & t>0 \\
0 & \mbox{otherwise} 
\end{array} \right. \]
\pause where 
\begin{itemize}
\item $\nu$ controls the smoothness of the spatial process ($\lfloor \nu \rfloor$ number of times process realizations are mean square differentiable) while 
\item $\phi$ is a spatial scale parameter. 
\end{itemize}
\pause Special cases are the exponential ($\nu=1/2$) and Gaussian ($\nu\to\infty$).
\end{frame}




\begin{frame}
\frametitle{Strong stationarity}
\begin{definition}
A process $Y(s)$ is \alert{strongly (or strictly) stationary} if, for any set of $n\ge 1$ sites $\{s_1,\ldots,s_n\}$ and any $h\in \mathbb{R}^d$, 
\[
(Y(s_1),\ldots,Y(s_n))^\top \stackrel{d}{=} (Y(s_1+h),\ldots,Y(s_n+h))^\top
\]
where $\stackrel{d}{=}$ means equal in distribution.
\end{definition}

\vspace{0.2in} \pause

If we assume all variances exist, then strong stationarity implies weak stationarity.

\vspace{0.2in} \pause

The reverse is not necessarily true. 

\end{frame}






\subsection{Gaussian process}
\begin{frame}
\frametitle{Gaussian process}
\begin{definition}
$Y(s)$ is a \alert{Gaussian process} if, for any $n\ge 1$ and any set of sites $\{s_1,\ldots,s_n\}$, $Y=(Y(s_1),\ldots,Y(s_n))^\top$ has a multivariate normal distribution.
\end{definition}

\vspace{0.2in} \pause 

For a Gaussian process, weak stationarity and strong stationarity are equivalent. 
\end{frame}





\subsection{Estimation}
\begin{frame}
\frametitle{Bayesian estimation of Gaussian process parameters}

Suppose we observe data at some locations $s_1,\ldots,s_n$. \pause Collectively, we have $y=(y(s_1),\ldots,y(s_n))$. \pause Let's assume the data arise from a Gaussian process \pause and according to a particular covariance function\pause. Collectively refer to the parameters as $\theta$, then our objective is
\[ 
p(\theta|y) \propto p(y|\theta)p(\theta).
\]

\vspace{0.2in} \pause

Suppose we assume the Mat\'{e}rn covariance function and a common mean $\mu$ so that $\theta = (\mu,\nu, \phi, \tau^2, \sigma^2)$. \pause Then we have 
\[ 
p(\mu,\nu,\phi,\tau^2,\sigma^2|y) \propto N(y;\mu,\mySigma)p(\mu,\nu, \phi, \tau^2, \sigma^2)
\]
\pause
where $\mySigma$ is constructed from the parameters $\nu$, $\phi$, $\tau^2$, and $\sigma^2$ and the distances between locations, e.g. $||s_1-s_2||$. 

\end{frame}




\frame{\frametitle{}
	Consider point-referenced data at spatial locations $s_1,\ldots,s_n$, model this data as 
	\[ Y(s) = \mu(s)+w(s)+\epsilon(s) \]
	If we constrain ourselves to isotropic models, the Mat\'{e}rn class is suggested as a general tool (Banerjee pg. 37). \pause If $w=(w(s_1),\ldots,w(s_n))^\top$ and $\epsilon=(\epsilon(s_1),\ldots,\epsilon(s_n))^\top$, then a general model is \pause
	\[ Var[w] = \sigma^2 H(\phi) \qquad Var[\epsilon] = \tau^2 \mathrm{I} \]
	\pause where $H$ is a correlation matrix with $H_{ij}=\rho(s_i-s_j;\phi)$ and $\rho$ is a valid isotropic correlation function on $\mathbb{R}^r$, i.e. Mat\'{e}rn:
	\[ \rho(u;\nu,\phi) = \frac{(u/\phi)^\nu K_\nu(u/\phi)}{2^{\nu-1}\mathrm\Gamma(\nu)} \]
	as defined in {\tt geoR:matern}. 
	\pause The overall mean is modeled separately and uses covariates $x(s)$ via \[\mu(s)=x(s)^\top\beta.\] 
}

\frame{\frametitle{Bayesian estimation for spatial random effects}
	Let $\theta=(\beta,\sigma^2,\tau^2,\phi)$, then parameter estimates may be obtained from the posterior distribution:
	\[ p(\theta|y) \propto p(y|\theta) p(\theta) \]
	\pause where 
	\[ Y|\theta \sim N(X\beta, \sigma^2 H(\phi)+\tau^2\mathrm{I}).\]
	
	\vspace{0.2in} \pause
	
	Typically, independent priors are chosen so that 
	\[ p(\theta) = p(\beta)p(\sigma^2)p(\tau^2)p(\phi). \]
	As a general rule, non-informative priors can be chosen for $\beta$, e.g. $p(\beta)\propto 1$. \pause However, improper (or vague proper) priors for the variance parameters can lead to improper (or computationally improper) posteriors.  
}



\subsection{Example}
\begin{frame}[fragile]
\frametitle{Diameter at breast height (DBH) for an experimental forest}
<<'DBH_data'>>=
library(spBayes)

## Load a dataset from spBayes. Remove rows with missing values
data(WEF.dat)
d <- WEF.dat[!apply(WEF.dat[,c("East_m","North_m", "DBH_cm","Tree_height_m","ELEV_m")], 1, function(x)any(is.na(x))),]

# Best guess at common name based on species code
d$Species = revalue(d$Species, c(DF = 'Douglas Fir', GF = 'Grand Fir', NF = 'Noble Fir', SF = 'Silver Fir', WH = 'Western Hemlock'))

g = ggplot(d, aes(East_m, North_m, size=DBH_cm)) + theme_bw()
g + geom_point(alpha=I(0.5))
@
\end{frame}





\begin{frame}
<<DBH_interval, dependson='WEF.dat'>>=
g + geom_point(alpha=I(0.5)) + 
  facet_wrap(~Species) 
@
\end{frame}


\begin{frame}
\frametitle{Interpolation of DBH (ignoring species)}
<<DBH_interpolation, message=FALSE>>=
## Load the MBA and fields libraries for creating surface interpolation plots
library(MBA)
library(fields) ## For using the image.plot function
x.res <- 100
y.res <- 100

col.br <- colorRampPalette(c("blue", "cyan", "yellow", "red"))
col.pal <- col.br(5)

surf <- mba.surf(d[c('East_m','North_m','DBH_cm')], no.X = x.res, no.Y = y.res, h = 5, m = 2, extend = FALSE)$xyz.est
image.plot(surf, xaxs = "r", yaxs = "r", xlab = "Easting (m)", ylab = "Northing (m)", col = col.br(25))
contour(surf, add=T) ## (Optional) Adds contour lines to the plot
@
\end{frame}




\begin{frame}[fragile]
\frametitle{OLS fit}
<<DBH_OLS>>=
## Load geoR library for computing variograms
library(geoR)
coords = d[c('North_m','East_m')]
max.dist <- 0.25 * max(iDist(coords))
bins <- 50

vario.DBH <- variog(coords = coords, data = d$DBH_cm, uvec = (seq(0, max.dist, length = bins)))
fit.DBH <- variofit(vario.DBH, ini.cov.pars = c(600,200/-log(0.05)), cov.model = "exponential", minimisation.function = "nls", weights = "equal")

## Run an OLS regression and make variograms from the residuals.
lm.DBH <- lm(DBH_cm ~ Species, data = d)
summary(lm.DBH)
DBH.resid <- resid(lm.DBH)
@
\end{frame}


\begin{frame}[fragile]
\frametitle{Variogram (exponential model)}
<<DBH_variogram, dependson='DBH_OLS', message=FALSE>>=
vario.DBH.resid <- variog(coords = coords, data = DBH.resid, uvec = (seq(0, max.dist, length = bins)), messages=FALSE)
fit.DBH.resid <- variofit(vario.DBH.resid, ini.cov.pars = c(300, 200/-log(0.05)), cov.model = "exponential", minimisation.function = "nls", weights = "equal", messages=FALSE)

opar = par(mfrow = c(1, 2))
plot(vario.DBH, ylim = c(200, 1200), main = "DBH")
lines(fit.DBH)
abline(h = fit.DBH$nugget, col = "blue")
abline(h = fit.DBH$cov.pars[1] + fit.DBH$nugget, col = "green")
abline(v = -log(0.05) * fit.DBH$cov.pars[2], col = "red3")
plot(vario.DBH.resid, ylim = c(200, 500), main = "DBH residuals")
lines(fit.DBH.resid)
abline(h = fit.DBH.resid$nugget, col = "blue")
abline(h = fit.DBH.resid$cov.pars[1] + fit.DBH.resid$nugget, col = "green")
abline(v = -log(0.05) * fit.DBH.resid$cov.pars[2], col = "red3")
par(opar)
@
\end{frame}


\begin{frame}[fragile]
\frametitle{Isotropy?}
<<DBH_directional_variograms>>=
### Illustrate variograms using the gstat package
library(gstat)
ELEV_m <- WEF.dat$ELEV_m
sp.dat <- as.data.frame(cbind(DBH, HT, coords, ELEV_m))
coordinates(sp.dat) <- c("East_m", "North_m")
vario.DBH <- variogram(DBH ~ ELEV_m, data = sp.dat,cutoff = max.dist, width = 5, alpha = (0:3) * 45)
fit.DBH <- fit.variogram(vario.DBH, vgm(1000, "Exp", 200/-log(0.05), 600))
print(plot(vario.DBH, fit.DBH))
@
\end{frame}


\frame{\frametitle{Spatial surface}
	If interest resides in $w$, draws can be obtained using the following relationship
	\[ p(w|y) = \int p(w|\sigma^2,\phi)p(\sigma^2,\phi|y) d\sigma^2 d\phi \]
	which suggests the following strategy:
	
	\vspace{0.2in} \pause
	
	\begin{enumerate}
	\item Run the MCMC sampler to obtain draws $(\sigma^2,\phi)^{(g)} \sim p(\sigma^2,\phi|y)$
	\item After burn-in and for $g=1,\ldots,G$, sample $w^{(g)}\sim p(w|(\sigma^2,\phi)^{(g)})$. 
	\end{enumerate}
}




\frame{\frametitle{Prediction}
	For prediction at points $s_{01},\ldots,s_{0m}$ and denoting $Y_0=(Y(s_{01}),\ldots,Y(s_{0m}))^\top$ and design matrix $X_0$ having rows $x(s_{0j})^\top$, \pause the following relationship
	\[ p(y_0|y,X,X_0) = \int p(y_0|y,\theta,X_0) p(\theta|y,X) d\theta \pause \approx \frac{1}{G} \sum_{g=1}^G p(y_0|y,\theta^{(g)},X_0). \]
	\pause It is more common to take draws $y_0^{(g)} \sim p(y_0|y,\theta^{(g)},X_0)$ and estimate the predictive distribution using 
	\[ p(y_0|y,,X_0)  \approx \frac{1}{G}  \sum_{g=1}^G \delta_{y_0^{(g)}} \]
	\pause where $p(y_0|y,\theta,X_0)$ has a conditional normal distribution.
}


\begin{frame}
\frametitle{Predictions are not conditionally independent}

Consider the joint distribution for $y$ and $y_0=y(s_0)$ (a scalar for simplicity), \pause then
\[ 
\left(\begin{array}{c} y \\ y_0 \end{array}\right) \sim N\left(\left[\begin{array}{c}X\beta \\ X_0\beta \end{array}\right],
\left[ \begin{array}{cc} \Omega_{11} & \Omega_{12} \\ \Omega_{21} & \Omega_{22} \end{array} \right]\right)
\]
\pause
where 
\[ \begin{array}{rl}
\Omega_{11} &= \sigma^2 H(\phi) + \tau^2 \I \\
\Omega_{22} &= \sigma^2 + \tau^2 \\
\Omega_{12}^\top &= \sigma^2(\rho(d_{01};\phi), \ldots, \rho(d_{0n};\phi))
\end{array} \]
and $d_{ij}=||s_i-s_j||$.

\vspace{0.2in} \pause

Thus $y_0|y,\theta,X,X_0$ is normal with 
\[ \begin{array}{rl}
E[Y(s_0)|y,\theta,X,X_0] &= x_0^\top \beta + \Omega_{12}^\top\Omega_{22}^{-1}(y-X\beta) \\
V[Y(s_0)|y,\theta,X,X_0] &= \sigma^2+\tau^2 - \Omega_{12}^\top\Omega_{22}^{-1}\Omega_{12}
\end{array} \]
\end{frame}





\begin{comment}
\subsection{Areal data}
\frame{\frametitle{Areal data}
	Let $y_i$ denote the observation for areal unit $i$, then we typically model this using 
	\[ Y_i = \mu_i + \phi_i + \epsilon_i \quad \mbox{equivalently} \quad Y = \mu+\phi+\epsilon \]
	\pause with a conditionally autoregressive (CAR) model 
	\[ \mu = X\beta \qquad \phi \sim N(0,\tau^2[D_w-\rho W]^{-1}) \qquad \epsilon \sim N(0,\sigma^2\mathrm{I}) \]
	\pause where $W$ is the proximity matrix and $D_w$ is a diagonal containing the row sums of $W$. \pause Alternatively for the CAR model, we can write 
	\[ p(\phi_i|\phi_j,i\ne j) = N\left(\rho \sum_j w_{ij} \phi_j/w_{i+}, \tau^2/w_{i+}\right) \]
	\pause which justifies the CAR name.
}

\frame{\frametitle{Choosing $W$}
	$W$ is a proximity matrix with $w_{ii}=0$ by definition. \pause
	Common choices for $w_{ij}$ are 
	\begin{itemize}[<+->]
	\item 1 if $i$ is a neighbor of $j$ and 0 otherwise
		\begin{itemize}
		\item neighbors defined by those who share an edge
		\item neighbors defined by those who share a point
		\item neighbors defined by those who are within distance $\delta$
		\item $K$-nearest neighbors
		\end{itemize}
	\item ``distance'' 
		\begin{itemize}
		\item inverse intercentroidal distance
		\item inverse minimum distance plus c
		\end{itemize}
	\end{itemize}
}

\frame{\frametitle{Dealing with $\rho$}
	The CAR model is only proper if $\rho \in (1/\lambda_{(1)},1/\lambda_{(n)})$ where $\lambda_{(1)}<\cdots<\lambda_{(n)}$ are the ordered eigenvalues of $D_w^{-1/2}WD_w^{-1/2}$. \pause So
	
	\vspace{0.2in} 
	
	\begin{itemize}[<+->]
	\item Choose $\rho$ so the CAR model is proper
	\item Choose $\rho=1$ (improper IAR model) and constrain $\sum_{i=1}^n \phi_i=0$
	\item Choose $\rho=1$ and estimate a mean (remove mean from the fixed effect)
	\item Let $\rho\sim Be(18,2)$ (Banerjee pg 164) and estimate it.
	\end{itemize}
}

\subsection{Generalized linear modeling}
\frame{\frametitle{GLMs}\pause
	\begin{itemize}[<+->]
	\item Binary data
		\begin{itemize}
		\item Point-referenced data: 
		\[ Y(s) \sim Ber(p(s)) \qquad \mbox{logit}(p(s)) = \mu(s)+w(s) \]
		\item Areal data
		\[ Y_i \sim Ber(p_i) \qquad \mbox{logit}(p_i) = \mu_i + \phi_i \]
		\end{itemize}
		
		\vspace{0.2in}
		
	\item Count data
		\begin{itemize}
		\item Point-referenced data: 
		\[ Y(s) \sim Po(\lambda(s)) \qquad \log(\lambda(s)) = \mu(s)+w(s) \]
		\item Areal data
		\[ Y_i \sim Po(\lambda_i) \qquad \log(\lambda_i) = \mu_i + \phi_i \]
		\end{itemize}
	\end{itemize}
}
\end{comment}

\end{document}

