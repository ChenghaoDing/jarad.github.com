---
layout: page
title: "Nonlinear estimation"
description: ""
group: 
---
{% include JB/setup %}

## Nonlinear estimation

We have data points $Y_i$ that are normally distributed (?) with a common 
variance and mean that is a non-linear function of an explanatory variable $X_i$ 
and a parameter $\lambda$. 
The value of $\lambda$ results in a particular derivative of the mean of $Y$ as 
a function of $X$. 
In particular the value $\lambda=1$ is of interest.
Thus the client is interested in estimating the derivative of the mean 
function.

## Questions

- Are there any bounds on $\lambda$?
- Is a normality assumption reasonable?
- Is a constant variance assumption reasonable?



## Comments

Although the client indicated they were interested in estimating the derivative,
it may be sufficient (or better) to directly estimate $\lambda$.

### Bayesian approach for posterior on $\lambda$ 

A Bayesian approach via MCMC could be employed to jointly estimate the variance
and $\lambda$ where the full conditional for $\lambda$ would not be available
in closed form. 
Thus, the $\lambda$ step could be a Metropolis-Hastings step or slice sampling 
step or something else.


### Derivative based on splines

One way to estimate the derivatives is to use splines. 
In this case it may be worthwhile to create a centered version of the data by
subtracting the mean when $\lambda=1$. 
Now, if $\lambda$ is truly 1, the derivative should be zero. 
Thus, when we construct confidence/credible intervals at any $X$ value, 
we can determine if these intervals contain 0.